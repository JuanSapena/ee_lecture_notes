\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% NEW CHAPTER
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Populations}
{\it 
The previous chapter developed a model of individual behaviour based on an
assumed dynamic imposed on wealth. If we know the stochastic process that describes
individual wealth, then we also know what happens at population level -- each individual
is represented by a realisation of the process, and we can compute 
the dynamics of wealth distributions. We answer questions about inequality and poverty in
our model economy. It turns out that our decision criterion generates interesting emergent
behaviour -- cooperation, the sharing and pooling of resources, is often time-average 
growth optimal. This provides answers to the puzzles of why people cooperate, why there 
is an insurance market, and why we see socio-economic structure from the formation of 
firms to nation states with taxation and redistribution systems.}
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Every man for himself}
\seclabel{Every_man}

We have seen that risk aversion constitutes optimal behaviour under the assumption 
of multiplicative wealth growth and over time scales that are long enough for systematic 
trends to be significant. In this chapter we will continue to explore our null model, 
GBM. By ``explore'' we mean that we will let the model generate its world -- if 
individual wealth was to follow GBM, what kind of features of an economy would emerge? 
We will see that cooperation and the formation of social structure also constitute 
optimal behaviour.

GBM is more than a random variable. It's a stochastic process, either a set of trajectories 
or a family of time-dependent random variables, depending on how we 
prefer to look at it.  Both perspectives are informative in the context of economic modelling:
from the set of trajectories we can judge what is likely to happen to an individual, 
\eg by following a single trajectory for a long time; while the PDF of the random 
variable $x(t^*)$ at some fixed value of $t^*$ tells us how wealth is distributed in our model. 

We use the term wealth distribution to refer to the density function 
$\PDF_x(x)$ (not to the process of distributing wealth among people). This can be 
interpreted as follows: if I select a random individual (each individual with uniform probability 
$\frac{1}{N}$), the probability of the selected individual 
having wealth greater than $x$ is given by the CDF $F_x(x)=\int_x^\infty \PDF_x(s)\,ds$.
In a large population of $N$ individuals, $\D x \PDF_x(x)N$ is the approximate 
number of individuals who have wealth between $x$ and $x+\D x$. 
Thus, a broad wealth distribution with heavy tails indicates greater wealth inequality.

\underline{Examples:}
\begin{itemize}
\item Under perfect equality everyone would have the same, meaning that the wealth
distribution would be a Dirac delta function centred at the sample mean of $x$, that is
\be
\PDF_x(x)=\delta(x-\ave{x}_N);
\ee
\item
Maximum inequality would mean that one individual owns everything
and everyone else owns nothing, that is
\be 
\PDF_x(x)=\frac{N-1}{N}\delta(x-0)+\frac{1}{N}\delta(x-N\ave{x}_N).
\ee
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Log-normal distribution}
\seclabel{Log-normal_wealth}
At a given time, $t$, GBM produces a random variable, $x(t)$, with a log-normal distribution whose parameters depend on $t$. (A log-normally distributed random variable is one whose logarithm is a normally distributed random variable.) If each individual's wealth follows GBM,
\be
dx=x(\mu dt + \sigma dW),
\elabel{GBM}
\ee
with solution 
\be
x(t) = x(0) \exp\left[\left(\mu-\frac{\sigma^2}{2}\right)t + \sigma W(t)\right],
\elabel{GBM_sol}
\ee
then we will observe a log-normal distribution of wealth at each moment in time:
\be
\ln x(t) \sim \mathcal{N}\left(\ln x(0) + \left(\mu - \frac{\sigma^2}{2}\right)t, \sigma^2 t\right).
\elabel{lognormal}
\ee
It will be convenient hereafter to assume the initial condition $x(0)=1$ (and, therefore, $\ln x(0)=0$) unless otherwise stated.

Note that the variance of $\ln x(t)$ increases linearly in time. We will develop an understanding of this shortly. As we will see, it indicates that any meaningful measure of inequality will grow over time in our simple model. To see what kind of a wealth distribution \eref{lognormal} is, it is worth spelling out the lognormal PDF:
\be
\PDF_x(x)=\frac{1}{x\sqrt{2\pi \sigma^2t}}\exp\left(-\frac{[\ln x-(\mu-\frac{\sigma^2}{2})t]^2}{2\sigma^2 t} \right).
\elabel{PDFx}
\ee

%The expectation value $\ave{\ln x}=\ln x_0 + \left(\mu - \frac{\sigma^2}{2}\right)t$ is
%given by \eref{lognormal}. It differs from the logarithm of the expectation value, 
%$\ave{\ln x}\neq \ln\ave{x}$, which we now compute.

This distribution is the subject of a wonderful book \cite{AitchisonBrown1957}, sadly out-of-print now. We will find it useful to know a few of its basic properties. Of particular importance is the expected wealth under this distribution. This is
\be
\ave{x(t)}=\exp(\mu t)
\elabel{exp_x}
\ee
or, equivalently, $\ln\ave{x(t)}=\mu t$. We could confirm this result by calculating $\ave{x(t)}=\int_0^\infty s\PDF_x(s)\,ds$, but this would be laborious. Instead we use a neat trick, courtesy of \cite[Chapter 4.2]{KloedenPlaten1992}, which will come in handy again in \secref{Wealth_tax}. To compute moments, $\ave{x^n}$, of stochastic differential equations for $x$, like \eref{GBM}, we find ordinary differential equations for the moments, which we know how to solve. For the first moment we do this simply by taking expectations of both sides of \eref{GBM}. The noise term vanishes to turn the SDE for $x$ into an ODE for $\ave{x}$:
\bea
\ave{dx}&=&\ave{x(\mu dt + \sigma dW)}\\
d\ave{x}&=&\ave{x} \mu dt + \sigma \overbrace{\ave{dW}}^{=0}\\
&=&\ave{x} \mu dt.
\eea
This is a very simple first-order linear differential equation for the expectation value of $x$. Its solution with initial condition $x(0)=1$ is \eref{exp_x}.

For $\mu>0$ the expected wealth grows exponentially over time, as do its population median and variance:
\bea
\text{median}[x(t)] &=& \exp[(\mu-\sigma^2/2)t]; \elabel{median_x} \\
\var[x(t)] &=& \exp(2\mu t)[\exp(\sigma^2 t)-1]. \elabel{var_x}
\eea

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Two growth rates}
\seclabel{two_rates}
We will recap briefly here one of our key ideas, covered in detail in \secref{Geometric_Brownian}, that the ensemble average of all possible trajectories of GBM grows at a different (faster) rate from that achieved by a single trajectory almost surely in the long-time limit. Understanding this difference was the key to developing a coherent theory of individual decision-making. We will see here that it is also crucial in understanding how wealth becomes distributed in a population of individuals whose wealths follow \elabel{GBM} and, in particular, how we can measure the inequality in such a distribution.

From \eref{expectation_g}, we recall that the growth rate of the expected wealth is
\be
\gex = \frac{d\ln\ave{x}}{dt} = \mu,
\ee
while, from \eref{time_g}, the time-average growth rate of wealth is
\be
\gt = \frac{d\ave{\ln x}}{dt} = \mu-\frac{\sigma^2}{2}.
\ee

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Measuring inequality}
\seclabel{Inequality_measure}
In the case of GBM we have just seen how to 
compute the exact full wealth distribution $\PDF$. This is interesting but often we want only summary measures of the distribution. One such summary measure of particular interest to economists is inequality. How much inequality is there in a distribution like \eref{lognormal}? And how does this quantity increase over time under GBM, as we have suggested?

Clearly, to answer these questions, we must quantify ``inequality''. In this section, and also in \cite{AdamouPeters2016}, we develop a natural way of measuring it, which makes use of the two growth rates we identified for the non-ergodic process. We will see that a particular inequality measure, known to economists as Theil's second index of inequality \cite{Theil1967}, is the difference between typical wealth (growing at the time-average growth rate) and average wealth (growing at the ensemble-average growth rate) in our model. Thus, the difference between the time average and ensemble average, the essence of ergodicity breaking, is the fundamental driver of the dynamics of inequality.

The two limits of inequality are easily identified: minimum inequality means that everyone 
has the same wealth, and maximum inequality means that one individual has all the 
wealth and everyone else has nothing. (This assumes that wealth cannot become 
negative.) Quantifying inequality in any other distribution is reminiscent of the gamble 
problem. Recall that for gambles we wanted make statements of the type ``this gamble 
is more desirable than that gamble''. We did this by collapsing a distribution to a 
scalar. Depending on the question that was being asked 
the appropriate way of collapsing the distribution and the resulting scalar can be different 
(the scalar relevant to an insurance company may not be relevant to an individual). 
In the case of inequality we also have a distribution -- the wealth distribution -- and we 
want to make statements of the type ``this distribution is more unequal than that 
distribution''. Again, this is done by collapsing the distribution to a scalar, and again 
many different choices of collapse and resulting scalar are possible. The Gini 
coefficient is a particularly well-known scalar of this type, the 80/20 ration is another, 
and many other measures exist.

In this context the expectation value is an important quantity. 
For instance, if everyone has the same wealth, everyone will own the average $\forall i, x_i=\ave{x}_N$,
which converges to the expectation value for large $N$. Also, whatever the distribution 
of wealth, the total wealth is $N\ave{x}_N$ which converges to $N\ave{x}$ as $N$ grows large. The growth 
rate of the expectation value, $\gex$, thus tells us how fast the average wealth and the 
total population wealth grow with probability one in a large ensemble. The time-average growth rate, $\gt$, on the other hand, tells us how fast an individual's wealth grows with probability one in 
the long run. If the typical individual's wealth grows at a lower rate than the 
expectation value of wealth then there must be atypical individuals with very large 
wealths that account for the difference. This insight suggests the following measure of 
inequality.

\definition{
Inequality, $J$, is the quantity whose growth rate is the 
difference between expectation-value and time-average growth rates,
\be
\frac{dJ}{dt}=\gex-\gt.
\elabel{dJ}
\ee
\Eref{dJ} defines the dynamic of inequality, and inequality itself is found by 
integrating over time:
\be
J(t)=\int_0^t ds [\gex(s)-\gt(s)].
\elabel{J}
\ee
}

This definition may be used for dynamics other than
GBM. Whatever the wealth dynamic, typical minus average growth rates are informative of the
dynamic of inequality. Within the GBM framework we can write the difference in growth rates as 
\be
\frac{dJ}{dt}=\frac{d \ln \ave{x}}{dt}-\frac{d \ave{\ln x}}{dt}
\elabel{J_dyn}
\ee
and integrate over time to get
\be
J(t)=\ln \ave{x}-\ave{\ln x}.
\ee
This quantity is known as the mean logarithmic deviation (MLD) or Theil's second index of inequality \cite{Theil1967}. 
This is rather remarkable. Our general inequality measure, \eref{J}, evaluated 
for the specific case of GBM, turns out to be a well-known measure of inequality that 
economists have identified independently, without considering non-ergodicity and ensemble 
average and time average growth rates. Merely by insisting on measuring inequality well,
Theil used the GBM model without realising it!

Substituting the known values of the two growth rates into \eref{dJ} and integrating, we can evaluate the Theil inequality as a function of time:
\be
J(t)=J(0)+\frac{\sigma^2}{2} t.
\elabel{J_t}
\ee
Thus we see that, in GBM, our measure of inequality increases indefinitely.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Wealth condensation}
\seclabel{condensation}
The log-normal distribution generated by GBM broadens indefinitely, \eref{var_x}. Likewise, the inequality present in the distribution -- measured as the time-integrated difference between ensemble and time average growth rates -- grows continually. A related property of GBM is the evolution towards wealth condensation. Wealth condensation means that a single individual will own a non-zero fraction of the total wealth in the population in the limit of large $N$, see \eg \cite{BouchaudMezard2000}. In the present case an arbitrarily large share of total wealth will be owned by an arbitrarily small share of the population.

One simple way of seeing this is to calculate the fraction of the population whose wealths are less than the mean, \ie $x(t)<\exp(\mu t)$. To do this, we define a new random variable, $z(t)$, whose distribution is the standard normal:
\be
z(t) \equiv \frac{\ln x(t) - (\mu-\sigma^2/2)t}{\sigma t^{1/2}} \sim \mathcal{N}(0,1).
\ee
We want to know the mass of the distribution with $\ln x(t)<\mu t$ or, equivalently, $z<\sigma t^{1/2}/2$. This is
\be
\Phi\left(\frac{\sigma t^{1/2}}{2}\right),
\ee
where $\Phi$ is the CDF of the standard normal distribution. This fraction tends to one as $t\to\infty$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Rescaled wealth}
\seclabel{rescaled}
Over the decades, economists have arrived at many inequality measures, and have drawn 
up a list of conditions that particularly useful measures of inequality satisfy. Such measures
are called ``relative measures'' \cite[Appendix 4]{Sen1997}, and $J$ is one of them. One of the conditions is that inequality measures
should not change when $x$ is divided by the same factor for everyone. Since we are primarily 
interested in inequality in this section it is useful to remove absolute wealth levels from the
analysis and study an object called the rescaled wealth.

\definition{
The rescaled wealth, 
\be
y=\frac{x}{\ave{x}_N},
\elabel{rescaled}
\ee
is the proportion of the population-average wealth owned by an individual.}

This quantity is useful, for instance because its numerical value does not 
depend on the currency used, it is a dimensionless number. 
Thus if my rescaled wealth, $y=1/2$, this means that my wealth is half the 
average wealth, irrespective of whether I measure wealth in Kazakhstani Tenge 
or in Swiss Francs. For a large population, \eref{J_dyn} may be expressed in 
terms of $y$ as $\frac{dJ}{dt}=-\frac{d\ave{\ln y}}{dt}$. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\subsubsection{$v$-normal distributions and Jensen's inequality}
%\seclabel{jensen}
%So far we have confined our analysis to GBM, where wealths follow the dynamic specific by \elabel{GBM}. However, as we discussed in the context of gambles, other wealth dynamics are possible. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Power law resemblance}
\seclabel{power_law}
It is an established empirical observation \cite{Newman2005} that the upper tails of 
real wealth distributions look more like a power law than a log-normal. Our trivial model does not
strictly reproduce this feature, but it is instructive to compare the lognormal distribution
to a power-law distribution. A power law PDF has the asymptotic form 
\be
\PDF_x(x)= x^{-\alpha},
\elabel{power_law}
\ee
for large arguments $x$. This implies that the logarithm of the PDF is proportional 
to the logarithm of its argument, $\ln \PDF_x(x) = -\alpha \ln x$. Plotting
one against the other will yield a straight line, the slope being the exponent $-\alpha$. 

Determining whether an empirical observation is consistent with such behaviour 
is difficult because the behaviour is to be observed in the tail (large $x$) where data are,
by definition, sparse. A quick-and-dirty way of checking for possible power-law 
behaviour is to plot an empirical PDF against its argument on log-log scales, 
look for a straight line, and measure the slope. However, plotting any distribution on any 
type of scales results in some line. It may not be a straight line but it will have some slope 
everywhere. For a known distribution (power law or not) we can interpret this slope 
as a local apparent power-law exponent. 

What is the local apparent power-law exponent of a log-normal wealth distribution near the 
expectation value $\ave{x}=\exp(\mu t)$, \ie in the upper tail where approximate power law behaviour
has been observed empirically? The logarithm of \eref{PDFx} is
\bea
\ln \PDF(x) =& -\ln\left(x\sqrt{2\pi \sigma^2t}\right) -\frac{[\ln x-(\mu-\frac{\sigma^2}{2})t]^2}{2\sigma^2 t}\\
=& -\ln x -\frac{\ln (2\pi \sigma^2t)}{2} - \frac{(\ln x)^2-2(\mu-\frac{\sigma^2}{2})t \ln x+(\mu-\frac{\sigma^2}{2})^2t^2}{2\sigma^2 t}.
\eea
Collecting terms in powers of $\ln x$ we find
\be
\ln \PDF(x)=-\frac{(\ln x)^2}{2\sigma^2 t}  + \left(\frac{\mu}{\sigma^2}-\frac{3}{2}\right)\ln x - \frac{\ln(2 \pi\sigma^2 t)}{2}-\frac{(\mu-\frac{\sigma^2}{2})^2t}{2\sigma^2}
\ee
with local slope, \ie apparent exponent,
\be
\frac{d\ln \PDF(x)}{d \ln x}= - \frac{\ln x}{\sigma^2 t}  + \frac{\mu}{\sigma^2} - \frac{3}{2}.
\ee
Near $\ave{x}$, $\ln x \sim \mu t$ so that the first two terms cancel approximately. Here the distribution will resemble a power-law with exponent $-3/2$ when plotted on doubly logarithmic scales. This is consistent with exponents between $-1.6$ and $-1.2$ measured from wealth data. (The distribution will also look like a power-law where the first term is much smaller than the others, \eg where $\ln x \ll \sigma^2 t$.) We don't believe that such empirically observed power laws are merely a manifestation of this mathematical feature. Important real-world  mechanisms that broaden real wealth distributions, \ie concentrate wealth, are missing from the null model. However, it is interesting that the trivial model of GBM reproduces so many qualitative features of empirical observations. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Finite populations}
\seclabel{finite_populations}
So far we have considered the properties the random variable, $x(t)$, generated by GBM at a fixed time, $t$. Most of the mathematical objects we have discussed are, strictly speaking, relevant only in the limit $N\to\infty$, where $N$ is the number of realisations of this random variable. For example, the expected wealth, $\ave{x(t)}$, is the limit of the sample mean wealth
\be
\ave{x(t)}_N \equiv \frac{1}{N}\sum_{i=1}^N x_i(t),
\elabel{sample}
\ee
as the sample size, $N$, grows large. In reality, human populations can be very large, say $N\sim10^7$ for a nation state, but they are most certainly finite. Therefore, we need to be diligent and ask what the effects of this finiteness are. In particular, we will focus on the sample mean wealth under GBM. For what values of $\mu$, $\sigma$, $t$, and $N$ is this well approximated by the expectation value? And when it is not, what does it resemble?

\subsubsection{Sums of lognormals\seclabel{sketch}}
In \cite{PetersKlein2013} we studied the sample mean of GBM, which we termed the ``partial ensemble average'' (PEA). This is the average of $N$ independent realisations the random variable $x(t)$, \eref{sample}. Here we sketch out some simple arguments about how this object depends on $N$ and $t$.

Considering the two growth rates in \secref{two_rates}, we anticipate the following tension:
\begin{enumerate}
\item[A)] for large $N$, the PEA should resemble the expectation value, $\exp(\mu t)$;
\item[B)] for long $t$, all trajectories in the sample -- and, therefore, the sample mean -- should grow like $\exp[(\mu-\sigma^2/2)t]$.
\end{enumerate}
Situation A -- when a sample mean resembles the corresponding expectation value -- is known in statistical physics as ``self-averaging.'' A simple strategy for estimating when this occurs is to look at the relative variance of the PEA,
\be
R \equiv \frac{\text{var}(\ave{x(t)}_N)}{\ave{\ave{x(t)}_N}^2}.
\ee
To be explicit, here the $\ave{\cdot}$ and $\text{var}(\cdot)$ operators, 
without $N$ as a subscript, 
refer to the mean and variance over all possible PEAs. The PEAs themselves, taken over finite samples of size $N$, are denoted $\ave{\cdot}_N$. Using standard results for the mean and variance of sums of independent random variables and inserting the results in \eref{exp_x} and \eref{var_x}, we get
\be
R(N) = \frac{e^{\sigma^2 t}-1}{N}.
\ee
If $R \ll 1$, then the PEA will likely be close to its own expectation value, which is equal to the expectation value of the GBM. Thus, in terms of $N$ and $t$, $\ave{x(t)}_N\approx\ave{x(t)}$ when
\be
t < \frac{\ln N}{\sigma^2}.
\elabel{short_t}
\ee
This hand-waving tells us roughly when the large-sample -- or, as we see from \eref{short_t}, short-time -- self-averaging regime holds. A more careful estimate of the cross-over time in \eref{t_c} is a factor of 2 larger, but the scaling is identical.

For $t>\ln N/\sigma^2$, the growth rate of the PEA transitions from $\mu$ to its $t\to\infty$ limit of $\mu-\sigma^2/2$ (Situation B). 
Another way of viewing this is to think about what dominates the average. For early times in the process, all trajectories are close together and none dominate the PEA. However, as time goes by the distribution broadens exponentially. Since each trajectory contributes with the same weight to the PEA, after some time the PEA will be dominated by the maximum in the sample,
\be
\ave{x(t)}_N \approx \frac{1}{N}\max_{i=1}^N \{x_i(t)\},
\ee
as illustrated in \fref{trajectories}.

Self-averaging stops when even the ``luckiest'' trajectory is no longer close to the expectation value $\exp(\mu t)$. This is guaranteed to happen eventually because the probability for a trajectory to reach $\exp(\mu t)$ decreases towards zero as $t$ grows. We know this from \secref{condensation}. Of course, this takes longer for larger samples, which have more chances to contain a lucky trajectory. 

\begin{figure}
\centering
\includegraphics[height=9.3cm]{./chapter_3/figs/trajectories.pdf}
\caption{PEA and maximum in a finite ensemble of size $N=256$. {\bf \underline{Red line:}} expectation value $\ave{x(t)}$. 
{\bf \underline{Green line:}} exponential growth at the time-average growth rate. In the $T\to\infty$ limit all trajectories grow at this rate. 
{\bf \underline{Yellow line:}} contribution of the maximum value of any trajectory at time $t$ to the PEA.  
{\bf \underline{Blue line:}} PEA $\ave{x(t)}_N$.
{\bf \underline{Vertical line:}} Crossover -- for $t>t_c=\frac{2\ln N}{\sigma^2}$ the maximum begins to dominate the PEA (the yellow line approaches the blue line).
{\bf \underline{Grey lines:}} randomly chosen trajectories -- any typical trajectory soon grows at the time-average growth rate.  
{\bf \underline{Parameters:}} $N=256$, $\mu=0.05$, $\sigma=\sqrt{0.2}$.}
\flabel{trajectories}
\end{figure}
\FloatBarrier

In \cite{PetersKlein2013} we analysed PEAs of GBM analytically and numerically. Using \eref{GBM_sol} the PEA can be written as
\be
\ave{x}_N=\frac{1}{N} \sum_{i=1}^N \exp\left[ \left(\mu-\frac{\sigma^2}{2}\right) t + \sigma \gW_i(t) \right],
\elabel{PEA}
\ee
where $\left\{\gW_i(t)\right\}_{i=1\dots N}$ are $N$ independent realisations of the Wiener process. Taking the deterministic part out of the sum we re-write \eref{PEA} as
\be
\ave{x}_N=\exp\left[ \left(\mu-\frac{\sigma^2}{2}\right) t \right] \frac{1}{N} \sum_{i=1}^N \exp\left(t^{1/2} \sigma \xi_i\right),
\elabel{PEA_2}
\ee
where $\left\{\xi_i\right\}_{i=1\dots N}$ are $N$ independent standard normal variates.

We found that typical trajectories of PEAs grow at $\gex$ up to a time $t_c$ 
that is logarithmic in $N$, meaning $t_c\propto \ln N$. This is consistent with our analytical sketch. After this time, typical 
PEA trajectories begin to deviate from expectation-value behaviour, and eventually 
their growth rate converges to $g_t$. While the two limiting behaviours $N\to\infty$
and $t\to \infty$ can be computed exactly, what happens in between
is less straightforward. The PEA is a random object outside these limits. 

A quantity of crucial interest to us is the exponential growth rate experienced by the PEA, 
\be
\gest(t,N) \equiv \frac{\ln(\ave{x(t)}_N)- \ln(x(0))}{t-0} = \frac{1}{t}\ln(\ave{x(t)}_N).
\elabel{gest}
\ee
In \cite{PetersKlein2013} we proved that the $t\to\infty$ limit for any (finite) 
$N$ is the same as for the case $N=1$, 
\be
\lim_{t\to\infty}\gest(t,N)=\mu-\frac{\sigma^2}{2}
\elabel{gest_2}
\ee
for all $N\geq1$. Substituting \eref{PEA_2} in \eref{gest} produces
\bea
\gest(t,N)&=&\mu-\frac{\sigma^2}{2}+\frac{1}{t} \ln\left(\frac{1}{N} \sum_{i=1}^N \exp( t^{1/2} \sigma \xi_i)\right)\\
&=&\mu-\frac{\sigma^2}{2}-\frac{\ln N}{t}+\frac{1}{t} \ln\left(\sum_{i=1}^N \exp( t^{1/2} \sigma \xi_i)\right).
\elabel{gest_4}
\eea

We didn't look in \cite{PetersKlein2013} at the expectation value of $\gest(t,N)$ for finite time and finite samples, but it's an interesting object that depends on $N$ and $t$ but is not stochastic. Note that this is not $\gest$ of the expectation value, 
which would be the $N\to\infty$ limit of \eref{gest}. Instead it is the 
$S\to\infty$ limit,
\be
\ave{\gest(t,N)} = \frac{1}{t}\ave{\ln(\ave{x(t)}_N)} = f(N,t),
\elabel{gest_3}
\ee
where, as previously, $\ave{\cdot}$ without subscript refers to the average over all possible samples, \ie $\lim_{S\to\infty}\ave{\cdot}_{S}$. The last two terms in \eref{gest_4} suggest an exponential relationship between ensemble size and time. The final term is a tricky stochastic object on which the properties of the expectation value in \eref{gest_3} will hinge. This term will be the focus of our attention: the sum of exponentials of normal random variates or, equivalently, log-normal variates.

\subsubsection{The random energy model}
Since the publication of \cite{PetersKlein2013} we have learned, thanks to discussions with J.-P.~Bouchaud, 
that the key object in \eref{gest_4} -- the sum log-normal random variates -- has been of
interest to the mathematical physics community since the 1980s. The reason for this is Derrida's random energy model \cite{Derrida1980,Derrida1981}.

It is defined as follows. Imagine a system whose energy levels are $2^K=N$ normally-distributed random numbers, $\xi_i$ (corresponding to $K$ spins). This is a very simple model of a disordered system, such as a spin glass, the idea being that the system is so complicated that we ``give up'' and simply model its energy levels as realisations of a random variable. (We denote the number 
of spins by $K$ and the number of resulting energy levels by $N$, while Derrida uses $N$ for the number of spins). In this model
The partition function is then
\be
Z=\sum_{i=1}^N \exp\left(\beta J\sqrt{\frac{K}{2}}\xi_i\right),
\elabel{Z}
\ee
where the inverse temperature, $\beta$, is measured in appropriate units, and the scaling in $K$ is chosen
so as to ensure an extensive thermodynamic limit \cite[p.~79]{Derrida1980}. $J$ is a constant that will be determined below.
The logarithm of the partition function gives the Helmholtz free energy, 
\bea
F&=&-\frac{\ln Z}{\beta}\\
&=&-\frac{1}{\beta}  \ln\left[\sum_{i=1}^N \exp\left(\beta J \sqrt{\frac{K}{2}}\xi_i\right)\right].
\elabel{F}
\eea

Like the growth rate estimator in \eref{gest}, this involves a sum of 
log-normal variates and, indeed, we can rewrite \eref{gest_4} as
\be
\gest=\mu-\frac{\sigma^2}{2}-\frac{\ln N}{t}-\frac{\beta F}{t},
\elabel{gest_5}
\ee
which is valid provided that
\be
\beta J \sqrt{\frac{K}{2}}=\sigma t^{1/2}.
\elabel{map}
\ee
\Eref{map} does not give a unique mapping between the parameters of our GBM, $(\sigma, t)$, and the parameters of the REM, $(\beta, K, J)$. Equating (up to multiplication) the constant parameters, $\sigma$ and $J$, in each model gives us a specific mapping:
\be
\sigma=\frac{J}{\sqrt{2}} \quad \text{and} \quad t^{1/2} = \beta\sqrt{K}.
\elabel{choice_1}
\ee

The expectation value of $\gest$ is interesting. The only random object
in \eref{gest_5} is $F$. Knowing $\ave{F}$ thus amounts to knowing $\ave{\gest}$.
In the statistical mechanics of the random energy model $\ave{F}$ is of key
interest and so much about it is known. We can use this knowledge
thanks to the mapping between the two problems.

Derrida identifies a critical temperature,
\be
\frac{1}{\beta_c} \equiv \frac{J}{2\sqrt{\ln 2}},
\elabel{beta_c}
\ee
above and below which the expected free energy scales differently with $K$ and $\beta$. This maps to a critical time scale in GBM,
\be
t_c = \frac{2\ln N}{\sigma^2},
\elabel{t_c}
\ee
with high temperature ($1/\beta>1/\beta_c$) corresponding to short time ($t<t_c$) and low temperature ($1/\beta<1/\beta_c$) corresponding to long time ($t>t_c$). Note that $t_c$ in \eref{t_c} scales identically with $N$ and $\sigma$ as the transition time, \eref{short_t}, in our sketch.

In \cite{Derrida1980}, $\ave{F}$ is computed in the high-temperature (short-time) regime as
\bea
\ave{F}&=&E-S/\beta \\
&=&-\frac{K}{\beta} \ln2 - \frac{\beta K J^2}{4},
\elabel{F_2}
\eea
and in the low-temperatures (long-time) regime as
\be
\ave{F}=-KJ\sqrt{\ln 2}.
\elabel{F_3}
\ee

\underline{Short time}\\
We look at the short-time behavior first (high $1/\beta$, \eref{F_2}).
The relevant computation of the entropy $S$ in \cite{Derrida1980} 
involves replacing the number of energy levels
$n(E)$ by its expectation value $\ave{n(E)}$. This is justified because
the standard deviation of this number is $\sqrt{n}$ and relatively small
when $\ave{n(E)}>1$, which is the interesting regime in Derrida's case. 

For spin glasses, the expectation value of $F$ is interesting, supposedly, 
because the system may be self-averaging and can be thought of as an
ensemble of many 
smaller sub-systems that are essentially independent. The macroscopic
behavior is then given by the expectation value.

Taking expectation values and substituting from \eref{F_2} in \eref{gest_5} we find
\be
\ave{\gest}^{\text{short}}=\mu-\frac{\sigma^2}{2}+\frac{1}{t} \frac{K J^2}{4T^2}.
\elabel{gest_6}
\ee
From \eref{map} we know that $t=\frac{KJ^2}{2\sigma^2T^2}$, which we substitute, to find
\be
\ave{\gest}^{\text{short}}=\mu,
\elabel{gest_7}
\ee
which is the correct behavior in the short-time regime.

\underline{Long time}\\
Next, we turn to the expression for the long-time regime (low temperature, \eref{F_3}). 
Again 
taking expectation values and substituting, this time from \eref{F_3} in \eref{gest_5}, we find
for long times
\be
\ave{\gest}^{\text{long}}=\mu-\frac{\sigma^2}{2}-\frac{\ln{N}}{t}+\sqrt{\frac{2\ln N}{t}}\,\sigma,
\elabel{gest_8}
\ee
which has the correct long-time asymptotic behavior.
The form of the correction to the time-average growth rate
in \eref{gest_8} is consistent with \cite{PetersKlein2013} and \cite{Redner1990}, where
it was found that approximately $N=\exp(t)$ systems are required for ensemble-average
behavior to be observed for a time $t$, so that the parameter $\ln N/t$ controls
which regime dominates -- if the parameter is small, then \eref{gest_8} indicates that the
long-time regime is relevant.

\Fref{1} is a direct comparison between the results derived
here, based on \cite{Derrida1980}, and numerical results using the same parameter 
values as in \cite{PetersKlein2013}, namely $\mu=0.05, \sigma=\sqrt{0.2}, N=256$ and $S=10^5$.

Notice that $\ave{\gest}$ is not the (local)
time derivative $\frac{\partial}{\partial t}\ave{\ln(\ave{x}_N)}$, but a time-average growth rate, $\ave{\frac{1}{t}\ln\left( \frac{\ave{x(t)}_N}{\ave{x(0)}_N}\right)}$. 
In \cite{PetersKlein2013} we used a notation that we've stopped using since then because it
caused confusion -- $\ave{g}$ there denotes the growth rate of the expectation value, which 
is not the expectation value of the growth rate. 

It is remarkable that the expectation value $\ave{\gest(N,t)}$ so closely reflects the
median, $q_{0.5}$, of $\ave{x}_N$, in the sense that
\be
q_{0.5}(\ave{x(t)}_N) \approx \exp \left(\ave{\gest(N,t)}t\right).
\elabel{quant_ave}
\ee
In \cite{PetersGell-Mann2016} it was discussed in detail that 
$\gest(1,t)$ is an ergodic observable for \eref{GBM}, in the sense that 
$\ave{\gest(1,t)}=\lim_{t\to\infty} \gest$. The relationship in \eref{quant_ave}
is far more subtle. The typical behavior of GBM PEAs 
is complicated outside the limits $N\to\infty$ or $t\to\infty$, in the sense that growth rates are 
time dependent here. This complicated behavior is well represented by an 
approximation that uses physical insights into spin glasses. Beautiful!

\begin{figure}
\centering
\includegraphics[height=9.3cm]{./chapter_3/figs/PEA.pdf}
\caption{Lines are obtained by exponentiating the various exponential 
growth rates. {\bf \underline{Blue line:}} $\ave{\ave{\gest}_{256}}_{10,000}$ is the numerical mean 
(approximation of the expectation value) 
over a super-ensemble of $S=10,000$ samples of $\gest$ estimated in sub-ensembles of $N=256$ GBMs each. 
{\bf \underline{Green line:}} median in a super-ensemble of $S$ samples of $\gest$, each estimated in sub-ensembles of size $N$. 
{\bf \underline{Yellow line:}} \eref{Ito_sums} is an exact expression for $d\ave{\ln\ave{x}_N}$, derived using \Ito calculus. We evaluate the expression by Monte Carlo, and integrate, $\ave{\ln\ave{x}_N}=\int_{0}^{t} d\ave{\ln\ave{x}_N}$. Exponentiation yields the yellow line. 
{\bf \underline{Red line:}} short-time behavior, based on the random energy model, \eref{gest_7}.
{\bf \underline{Purple line:}} long-time behavior, based on the random energy model, \eref{gest_8}. {\bf \underline{Vertical line:}} Crossover between the regimes at $t_c=\frac{2\ln N}{\sigma^2}$, corresponding to $\beta_c=\frac{2(\ln 2)^{1/2}}{J}$.
{\bf \underline{Parameters:}} $N=256$, $S=10,000$, $\mu=0.05$, $\sigma=\sqrt{0.2}$.}
\flabel{1}
\end{figure}
\FloatBarrier

%\subsubsection{Discussion}
%The \Ito result is exact. A Monte-Carlo estimate of \eref{Ito_sums} (which is easy to obtain) is 
%shown in \fref{1} (yellow line). This agrees well with numerical observations.
%The approximations from the random energy model have the right shape and asymptotic behavior, 
%though they're not on the same scale as the median PEA. This is, of course, not surprising because
%these estimates are not designed to coincide with the median PEA. Quantitatively they are closer to 
%a higher quantile of the distribution of PEAs. An intriguing question is this: is our computation 
%using \Ito calculus helpful to compute the expected free energy of the random energy model? 

\newpage

\begin{comment}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% NEW CHAPTER
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Interactions}
{\it
Insert abstract here.
}
\newpage

\subsection{Cooperation}
\seclabel{Cooperation}
Under multiplicative growth, fluctuations are undesirable because they reduce 
time-average growth rates. In the long run, wealth $x_1(t)$ with noise term 
$\sigma_1$ will outperform wealth $x_2(t)$ with a larger 
noise term $\sigma_2>\sigma_1$, in the sense that 
\be
\gt(x_1) > \gt(x_2)
\ee
with probability 1.

For this reason it is desirable to reduce fluctuations. One protocol that achieves this is 
resource pooling and sharing. In \secref{Every_man} we explored the world created 
by the model of independent GBMs. This is a world where everyone experiences the 
same long-term growth rate. We want to explore the effect of the invention of 
cooperation. As it turns out cooperation increases growth rates, and this is a 
crucial insight. 

Suppose two individuals, $x_1(t)$ and $x_2(t)$ decide to meet up every Monday, put all 
their wealth on a table, divide it in two equal amounts, and go back to their business, \ie
they submit their wealth to our toy dynamic \eref{GBM}. How 
would this operation affect the dynamic of the wealth of these two individuals?

 Consider a discretized version of \eref{GBM}, such as would be used in a numerical simulation. The non-cooperators grow according to
 \bea
 \d x_i(t) & = & x_i(t) \left[\mu \dt + \sigma \sqrt{\dt}\,\xi_i\right], \elabel{discrete_nonc_grow} \\
 x_i(t+\dt) & = & x_i(t) + \d x_i(t), \elabel{discrete_nonc_coop}
 \eea
 where $\xi_i$ are standard normal random variates, $\xi_i\sim \mathcal{N}(0,1)$.

We imagine that the two previously non-cooperating entities, with resources $x_1(t)$ and $x_2(t)$, cooperate to produce two entities, whose resources we label $x^c_1(t)$ and $x^c_2(t)$ to distinguish them from the non-cooperating case. We envisage equal sharing of resources, $x^c_1=x^c_2$, and introduce a cooperation operator, $\oplus$, such that
 \be
 x_1 \oplus x_2 = x^c_1 + x^c_2.
 \ee
 
 In the discrete-time picture, each time step involves a two-phase process. First there is a growth phase, analogous to \eref{GBM}, in which each cooperator increases its resources by
 \be
 \d x^c_i(t) = x^c_i(t)\left[\mu\dt + \sigma\sqrt{\dt}\,\xi_i\right].
 \elabel{discrete_coop_grow}
 \ee
 This is followed by a cooperation phase, replacing \eref{discrete_nonc_coop}, in which resources are pooled and shared equally among the cooperators:
 \be
 x^c_i(t+\dt) = \frac{ x^c_1(t) + \d x^c_1(t) + x^c_2(t) + \d x^c_2(t)}{2}.
 \elabel{discrete_coop_coop}
 \ee
 
 \begin{figure}
 \centering
 \begin{picture}(300,230)(60,0)
 \put(-20,0){\includegraphics[width=470pt]{./chapter_3/figs/blobs.pdf}}
 \put(0,145){$x^c_1(t)$}
 \put(48,147){\vector(1,0){45}}
 \put(0,40){$x^c_2(t)$}
 \put(48,40){\vector(1,0){75}}
 %
 \put(115,145){$x^c_1(t)+\d x^c_1(t)$}
 \put(200,147){\vector(3,-2){30}}
 \put(138,46){$x^c_2(t)$}
 \put(130,34){$+\d x^c_2(t)$}
 \put(173,45){\vector(3,2){50}}
 %
 \put(255,100){$x^c_1(t)+\d x^c_1(t)$}
 %
 \put(250,85){$+ x^c_2(t)+\d x^c_2(t)$}
 \put(335,75){\vector(3,-2){30}}
 \put(335,117){\vector(3,2){30}}
 %
 \put(385,145){$x^c_1(t+\dt)$}
 \put(385,40){$x^c_2(t+\dt)$}
 %
 \put(448,147){\vector(1,0){25}}
 \put(448,40){\vector(1,0){25}}

 \put(476,144.5){$\cdots$}
 \put(476,37.5){$\cdots$}
 % AA extra arrows
 \put(-47,117){\vector(3,2){25}}
 \put(-47,75){\vector(3,-2){25}}
 \put(-62,114){$\cdots$}
 \put(-62,73){$\cdots$}
 %
 \put(50,207.5){\large{Grow}}

 \put(215,190){$\overbrace{\text{Pool} \hspace{3cm}\text{Share}}^{\text{\large{Cooperate}}}$}

 \end{picture}
 \caption{Cooperation dynamics. Cooperators start each time step with equal resources, then they {\it grow} independently 
 according to \eref{discrete_coop_grow}, then they {\it cooperate} by {\it pooling} resources and {\it sharing} them equally, 
 then the next time step begins. 
  }
 \flabel{dynamics}
 \end{figure}
 

 %Analysis
 With this prescription both cooperators and their sum experience the following dynamic:
 \be
 (x_1 \oplus x_2)(t+\dt) =
 (x_1 \oplus x_2)(t) \left[1 + \left(\mu \dt + \sigma \sqrt{\dt} \, \frac{\xi_1 + \xi_2}{2}\right)\right].
 \elabel{discrete_cooperate}
 \ee
 For ease of notation we define
 \be
 \xi_{1\oplus2}=\frac{\xi_1+\xi_2}{\sqrt{2}},
 \ee
 which is another standard Gaussian, $\xi_{1\oplus2} \sim \mathcal{N}(0,1)$. Letting the time
 increment $\dt \to 0$ we recover an equation of the same form as
 \eref{GBM} but with a different fluctuation amplitude,
 \begin{equation}
 d(x_1 \oplus x_2) = (x_1 \oplus x_2)\left(\mu dt +\frac{\sigma}{\sqrt{2}} dW_{1\oplus2}\right).
 \end{equation}
 
The expectation values of a non-cooperator, $\ave{x_1(t)}$, and a corresponding cooperator,
$\ave{x^c_1(t)}$, are identical. Based on expectation values, we thus cannot 
 see any benefit of cooperation. Worse still, immediately after the growth phase, the 
 better-off entity of a cooperating pair, $x^c_1(t_0)>x^c_2(t_0)$, say, would increase its expectation value from 
$\frac{x^c_1(t_0)+x^c_2(t_0)}{2}\exp(\mu (t-t_0))$ to $x^c_1(t_0)\exp(\mu (t-t_0))$
by breaking the cooperation. But it would be foolish to act on the basis of this analysis --
the short-term gain from breaking cooperation is a one-off, and is dwarfed by the long-term
multiplicative advantage of continued cooperation. 
An analysis based on expectation values finds that there is no reason for 
cooperation to arise, and that if it does arise there are good reasons for it to end, 
\ie it will be fragile. Because expectation values are inappropriately used to evaluate 
future prospects, the observation of widespread cooperation constitutes a conundrum. 

%Solution of the cooperation conundrum
The solution of the conundrum comes from considering the time-average
growth rate. The non-cooperating entities grow at $g_{t}(x_i)=\mu-\frac{\sigma^2}{2}$, 
whereas the cooperating unit benefits from a reduction of the amplitude of relative 
fluctuations and grows at $g_{t}(x_1\oplus x_2)=\mu-\frac{\sigma^2}{4}$, 
and we have
\begin{equation}
g_{t}(x_1\oplus x_2)>g_{t}(x_i)
\end{equation}
for any non-zero noise amplitude. Imagine a world where cooperation does not exist, 
just like in \secref{Every_man}. Now introduce into this world two individuals who have 
invented cooperation -- very quickly this pair of individuals will be vastly more wealthy than
anyone else. To keep up, others will have to start cooperating. The effect is illustrated 
in \fref{cooperate} by direct simulation of
\eref{discrete_nonc_grow}--\eref{discrete_nonc_coop} and \eref{discrete_cooperate}.

\begin{figure}
\begin{picture}(200,300)(0,0)
\put(-35,-135){\includegraphics[width=440pt]{./chapter_3/figs/cooperate.pdf}}
\end{picture}
\caption{Typical trajectories for two non-cooperating (green) entities and for the 
corresponding cooperating unit (blue).
Over time, the noise reduction for the cooperator leads to faster growth. Even without
effects of specialisation or the emergence of new function, 
cooperation pays in the long run. The black thin line shows the average of the 
non-cooperating entities. While in the logarithmic vertical scale the average traces
the more successful trajectory, it is far inferior to the cooperating unit. 
In a very literal mathematical sense the whole, $(x_1 \oplus x_2)(t)$, is more than the sum of its
parts, $x_1(t)+x_2(t)$. The algebra of cooperation is not merely that of summation.}
\flabel{cooperate}
\end{figure}

Imagine again the pair of cooperators outperforming all of their peers. Other
entities will have to form pairs to keep up, and the obvious next step is for larger
cooperating units to form -- groups of 3 may form, pairs of pairs, cooperation 
clusters of $n$ individuals, and the larger the cooperating group the closer the
time-average growth rate will get to the expectation value.
For $n$ cooperators, $x_1\oplus x_2 ... \oplus x_n$ the spurious drift term is 
$-\frac{\sigma^2}{2n}$, so that the time-average growth approaches 
expectation-value growth for large $n$. The approach to this upper bound as 
the number of cooperators increases favours the formation of social structure. 

We may generalise to different drift 
terms, $\mu_i$, and noise amplitudes, $\sigma_i$, for different individual entities. 
Whether cooperation is beneficial in the long run for any
given entity depends on these parameters as follows. Entity 1 
will benefit from cooperation with entity 2 if 
\be
\mu_1-\frac{\sigma_1^2}{2}<\frac{\mu_1+\mu_2}{2}-\frac{\sigma_1^2+\sigma_2^2}{8}.
\ee
We emphasize that this inequality may be satisfied also if the expectation value
of entity 1 grows faster than the expectation value of entity 2, \ie if
$\mu_1>\mu_2$. An analysis of expectation values, again, is utterly misleading:
the benefit conferred on entity 1 due to the fluctuation-reducing effect of 
cooperation may outweigh the cost of having to cooperate with an entity with
smaller expectation value.
 
Notice the nature of the Monte-Carlo simulation in \fref{cooperate}. No ensemble
is constructed. Only individual trajectories are simulated and run for a time that is 
long enough for statistically significant features to rise above the noise. This method
teases out of the dynamics what happens over time. The significance of any observed 
structure -- its epistemological meaning -- is immediately clear: this is what happens over time
for an individual system (a cell, a person's wealth, {\it etc.}). Simulating an ensemble
and averaging over members to remove noise does not tell the same story. The resulting
features may not emerge over time. They are what happens on average in an ensemble, 
but -- at least for GBM -- this is not what happens to the individual with probability 1. For instance the 
 pink dashed line in \fref{cooperate} is the ensemble average of $x_1(t)$, $x_1(t)$, 
 and $(x_1 \oplus x_2)(t)/2$, and it has nothing to do with what happens 
 in the individual trajectories over time.

When judged on expectation values, the apparent futility of cooperation is unsurprising
because expectation values are the result for infinitely 
many cooperators, and adding further cooperators cannot improve on this.

In our model the advantage of cooperation, and hence the emergence
of social structure in the broadest sense -- is purely a non-linear 
effect of fluctuations -- cooperation reduces the magnitude of 
fluctuations, and over time (though not in expectation) this implies faster growth. 


Another generalisation is partial cooperation -- entities may share only
a proportion of their resources, resembling taxation and redistribution. We discuss this in the next section.

\subsection{\seclabel{Taxation}Taxation}
In \secref{Every_man} we created a world of independent GBMs; in \secref{Cooperation} 
we introduced to this world
the invention of cooperation and saw that it increases long-time growth for those who participate
in resource-pooling and sharing. In this section we study what happens if a large number
of individuals pool and share a small fraction of their resources, which is reminiscent of taxation
and redistribution carried out in a large population. We will find that while cooperation for 2 individuals
increases their growth rates, sufficient cooperation in a large population
has two related effects. Firstly, everyone's wealth grows asymptotically at a rate close to that of
the expectation value. Secondly, wealth condensation and the divergence of inequality 
no longer occur.

We introduce a model that applies a flat wealth tax rate and every individual, irrespective of his 
wealth, receives the same benefit from the collected tax, in absolute terms. This mimicks the
actions of a central agency that collects each year from everyone 1\% of his wealth and pays 
1-$N^\text{th}$ of the total collected amount to each individual. A similar model will be 
used for income tax, see \eref{isde} in \secref{Income_tax}. 

Of course this isn't how taxation works in reality -- wealth taxes are usually only collected in 
the form of inheritance tax and sometimes property or land tax; often progressive rates are 
applied, and how tax takings are actually redistributed is very unclear. 
Who benefits from government activity? Infrastructure is built, benefits payments made, 
healthcare and education provided, a legal system is maintained of courts that can 
enforce contracts and enable corporate structures, police and an army may provide security. 
Individuals will benefit from these different aspects to very different degrees. Our model 
ignores this and lets everyone benefit equally.

Despite the simplicity of the setup the following important feature emerges:
there is a critical tax rate. This qualitative result applies both to income tax and to wealth tax.

\definition{ {\bf Critical tax rate}\\
Below the critical tax rate the variance of rescaled wealth increases indefinitely. 
Above the critical tax rate it stabilizes to an asymptotic value in the limit $t\to\infty$.
}

\Secref{Cooperation} was concerned with growth, here we are concerned with inequality. 
We will therefore work with the rescaled wealth, $y$, introduced in \eref{rescaled}. \Eref{GBM} defines the 
dynamic of $x$. From it we can find the dynamic for $f(x)=y$ using \Ito calculus
\bea
df &=& \frac{\partial f}{\partial x} dx + \frac{\partial f}{\partial t} + \frac{1}{2} \frac{\partial^2 f}{\partial x^2} dx^2\\
=dy&=& -\mu y dt + \frac{y}{x} dx\\
&=&y \sigma dW.
\eea



\subsubsection{Wealth tax}
\seclabel{Wealth_tax}
We investigate the situation where each individual's wealth is taxed at a rate of $0\leq\tau\leq1$ per unit time, 
and the total tax thus raised is redistributed equally among the population. This is modelled by the stochastic wealth process,
\be
dx = x[(\mu-\tau)\,dt + \sigma\,dW] + \tau\ave{x}_N dt,
\elabel{wsde}
\ee
which is a modified version of \eref{GBM} -- the term $-\tau x dt$ was added to represent tax 
collection, and the term $+\tau \ave{x}_N dt$ to represent redistribution of collected tax.
To make the model more tractable we consider the case $N \to \infty$, which replaces the finite-ensemble 
average by the expectation value, $\ave{x}_N \to \ave{x}$. The finite ensemble size has important effects but 
we will not discuss them here.
Total wealth is conserved by the taxation and redistribution process in this model, 
and the expectation value is unaffected, $\ave{x(t)}=\ave{x_0}e^{\mu t}$, just as for GBM without taxation, \eref{exp_x}. 
We are again interested in rescaled wealth, $y=\frac{x}{\ave{x}}=x e^{-\mu t}$ (\eref{rescaled}), whose dynamic we derive using the chain rule
\bea
dy &=& \frac{\partial y}{\partial t}\,dt + \frac{\partial y}{\partial x}\,dx + \frac{1}{2} \frac{\partial^2 y}{\partial x^2} \,dx^2 \\
&=& -\mu y\,dt + \frac{1}{x}\,dx \elabel{ysde} \\
&=& y(-\tau dt+ \sigma dW)+\tau dt.
\eea
The first moment of $y$ is trivially $1$,
\be
\ave{y}=\ave{\frac{x}{\ave{x}}}=1.
\ee
We compute the dynamic of the second moment of $y$, to first order in $dt$, using the chain rule again,
\bea
d(y^2)&=& \frac{\partial (y^2)}{\partial t}\,dt + \frac{\partial (y^2)}{\partial y}\,dy + \frac{1}{2} \frac{\partial^2 (y^2)}{\partial y^2} \,(dy)^2\\
&=&2y dy + (dy)^2\\
&=& 2y^2(-\tau dt+ \sigma dW)+2y\tau dt +y^2\sigma^2 dt.
\eea
Taking expectation values yields 
\bea
\ave{dy^2}&=& \ave{-2y^2(-\tau dt+ \sigma dW)+2y\tau dt -y^2\sigma^2dt}\\
=d\ave{y^2}&=&(\sigma^2-2\tau) \ave{y^2} dt + 2\tau dt.
\eea
This equation is an inhomogeneous first-order ordinary differential equation for 
the second moment. Perhaps it's more recognizable when written in standard form as
\be
\left(\frac{d}{dt}- (\sigma^2-2\tau)\right)\ave{y^2}= 2\tau.
\elabel{ODE2}
\ee
Such equations are solvable using the method of integrating factors, see \eg \cite[Chpater 1.5]{BenderOrszag1978}.
The solution of the dynamic \eref{ODE2} is the second moment 
of the distribution of rescaled wealth as a function of time, namely
\be
\ave{y^2} = \frac{2\tau}{2\tau-\sigma^2} + \left(\ave{y_0^2} - \frac{2\tau}{2\tau-\sigma^2}\right) e^{-(2\tau-\sigma^2)t}.
\ee
This can be rewritten in terms of the variance of rescaled wealth, $V=\ave{y^2}-1$, as
\be
V(t) = V_\infty + (V_0 - V_\infty) e^{-(2\tau-\sigma^2)t},
\elabel{wvar}
\ee
where $V_0$ is the initial variance and
\be
V_\infty \equiv \frac{\sigma^2}{2\tau-\sigma^2}.
\ee
$V$ converges in time to the asymptote, $V_\infty$, provided the exponential in \eref{wvar} is decaying. This can be expressed as a condition on $\tau$,
\be
\boxed{
\tau > \tau_c \equiv \frac{\sigma^2}{2},
}
\elabel{wstab}
\ee
which defines the critical tax rate, $\tau_c$. Above this critical tax rate, $\tau>\tau_c$, the 
variance of the rescaled-wealth distribution stabilises. Below it, the variance grows beyond all bounds.
We believe that the divergence or convergence of the variance signals an important change
in systemic behavior, but we hasten to point out the following caveat: a finite second moment 
does not guarantee finiteness of higher moments. A deeper analysis of ODEs of the type of 
\eref{ODE2}, which we don't reproduce here, reveals that any finite wealth tax rate implies
that all moments of order $n>\frac{2\tau}{\sigma^2}+1$ diverge. Under the flat 
wealth tax investigated here, the wealth distribution never fully stabilizes. In the language often
used by economists in this debate, an ergodic wealth distribution does not exist for our model.

Caveats aside, \eref{wvar} also allows us to identify a characteristic timescale over 
which the variance stabilises for supercritical taxation,
\be
T_s = \frac{1}{2\tau-\sigma^2}.
\ee
$\tau_c$ may be viewed as the tax rate at which $T_s$ diverges.

Numerical simulations confirm that the above analytical results are informative for finite ensembles. 
\fref{var_wealth} compares the 
evolution of the empirical variance of the rescaled wealths of $N=10^4$ realisations of the 
stochastic wealth process in \eref{wsde} with the theoretical result for the infinite ensemble 
in \eref{wvar}. Parameter values were $\mu=0.05$, $\sigma^2=0.02$, and $\tau=0.1$ per 
unit time, of which the first two are realistic for a time unit of one year \cite{PetersAdamou2013} 
(assuming individual wealth processes share parameters with stock market indices). The 
differences are finite-sample effects.
\begin{figure}
\bc
\includegraphics[width=0.8\textwidth]{./chapter_3/figs/var_wealth.pdf}
\caption{Wealth tax. The empirical variance of the rescaled wealths of $N=10^4$ realisations of 
\eref{wsde} with uniformly-distributed initial wealths (red); the theoretical variance for the infinite 
ensemble, $V(t)$ (blue dashed); and the asymptotic theoretical variance, $V_\infty$ (black dotted). 
Parameter values are $\mu=0.05$, $\sigma^2=0.02$, and $\tau=0.1$ per unit time.}
\flabel{var_wealth}
\ec
\end{figure}
\fref{hist_wealth} shows the initial distribution of rescaled wealths, which was chosen to be uniform, 
and the final distribution at the end of the period shown in \fref{var_wealth}.
\begin{figure}
\bc
\includegraphics[width=0.8\textwidth]{./chapter_3/figs/hist_wealth.pdf}
\caption{Histograms of the initial (left) and final (right) empirical distributions of the rescaled 
wealth for the same realisations of \eref{wsde} used in \fref{var_wealth}.}
\flabel{hist_wealth}
\ec
\end{figure}

The simulated parameter values give a critical tax rate of 1\% pa. This is broadly in line 
with genuine annual wealth and property taxes in the few countries in which they are 
levied. Under the simulated tax rate of 10\% pa, the stabilisation time is $T_s\approx6$ 
years. It is hard to imagine a wealth tax of this magnitude being politically feasible in the 
real world. In our simple model, the tax rate could be set either to achieve convergence 
of inequality to a desired level, reflected by $V_\infty$, or over a desired timescale, 
represented by $T_s$.

It is interesting to connect this with the most widely levied wealth tax: the inheritance 
tax. In the UK this is levied at 40\% of the value of an individual's estate (above a 
certain threshold) upon death. We can surmise that an individual will typically hold 
most of his wealth for the human generation time of around 30 years, this being a 
sensible estimate of the time between inheriting or otherwise accumulating his wealth 
and passing it on. Using our plausible parameter values, an inheritance tax of 40\% 
corresonds to an annually compounded wealth tax of $1-(0.6)^{1/30} \approx 1.7\%$ 
pa and a stabilisation time of around 70 years. The former is close to and, notably, 
above the critical rate of 1\% pa, suggesting that variance stabilisation may be an 
influential criterion in the determination of our taxes.

\subsubsection{Income tax}
\seclabel{Income_tax}
In our very simple model, we have seen that a flat wealth tax can stabilize
the variance of the rescaled-wealth distribution. In this section we show 
that in a similarly simple model an income tax can achieve the same result. 
We introduce a model of income tax under which a fraction, $0\leq\tau\leq1$, of 
each individual's determinsitic wealth increment, $\mu x\,dt$, is deducted and 
the total tax raised is redistributed equally. This is modelled by the stochastic wealth process,
\be
dx = x[\mu(1-\tau)\,dt + \sigma\,dW] + \mu\tau\ave{x}_N dt.
\elabel{isde}
\ee
Again, we consider the large-population limit $N\to\infty$, corresponding to the replacement 
$\ave{x}_N\to\ave{x}$. For positive drift, $\mu>0$, the deterministic increment, $\mu x\,dt$, is guaranteed to 
be positive. It can be thought of as the income derived from that individual's activities, 
such as employment, on which governments typically levy taxes. Note that $\tau$ in \eref{isde} is a dimensionless number, whereas it is
a rate of dimension ``per unit time'' in \eref{wsde}. The form of 
\eref{isde} is identical to \eref{wsde} with the parameter transformation 
$\tau\rightarrow\mu\tau$. Thus we can immediately deduce the dynamic for the rescaled wealth as
\be
dy = y(-\mu\tau\,dt + \sigma\,dW) + \mu\tau\,dt.
\elabel{itax}
\ee
The variance stabilisation condition analogous to \eref{wstab} becomes
\be
\boxed{
\tau > \tau_c \equiv \frac{\sigma^2}{2\mu}.
}
\elabel{icrit}
\ee
This defines the critical income tax, $\tau_c$, above which the variance converges to its asymptotic value,
\be
V_\infty = \frac{\sigma^2}{2\mu\tau-\sigma^2},
\ee
according to
\be
V(t) = V_\infty + (V_0 - V_\infty) e^{-(2\mu\tau-\sigma^2)t}.
\elabel{ivar}
\ee
Finally, the stabilisation time is
\be
T_s = \frac{1}{2\mu\tau - \sigma^2}.
\ee

\fref{var_income} compares the evolution of the empirical variance of the rescaled wealths of $10^4$ realisations of the stochastic wealth process in \eref{isde} with the theoretical result for the infinite ensemble. Parameter values were $\mu=0.05$ and $\sigma^2=0.02$ per unit time, and $\tau=0.45$. The latter is the UK's limiting income tax rate for large incomes, which will be the determining tax rate for variance stabilisation.
\begin{figure}
\bc
\includegraphics[width=0.8\textwidth]{./chapter_3/figs/var_income.pdf}
\caption{Income tax. The empirical variance of the rescaled wealths of $10^4$ realisations of \eref{isde} with uniformly-distributed initial wealths (red); the theoretical variance for the infinite ensemble, $V(t)$ (blue dashed); and the asymptotic theoretical variance, $V_\infty$ (black dotted). Parameter values are $\mu=0.05$ and $\sigma^2=0.02$ per unit time, and $\tau=0.45$.}
\flabel{var_income}
\ec
\end{figure}

The finite-sample deviations from the infinite-ensemble result are larger in \fref{var_income} 
than in \fref{var_wealth}. This is due entirely to the simulated parameter values: \eref{wsde} 
and \eref{isde} can be made equivalent by choosing different parameters. 

\fref{hist_income} shows the initial distribution of rescaled wealths, which was chosen to be uniform, and the final distribution at the end of the period shown in \fref{var_income}.
\begin{figure}
\bc
\includegraphics[width=0.8\textwidth]{./chapter_3/figs/hist_income.pdf}
\caption{Histograms of the initial (left) and final (right) empirical distributions of the rescaled wealth for the same realisations of \eref{itax} used in \fref{var_income}.}
\flabel{hist_income}
\ec
\end{figure}
The distribution of wealths under income tax has an appreciably longer tail than under wealth tax. As before this is a function of the parameter choices. The simulated parameter values have a critical income tax rate of $\tau_c=0.2$ and a stabilisation time of $T_s=40$ years. Thus the UK sets its income tax at a level which, at least in this simple framework, has a variance stabilising effect.

\subsection{Reallocation}\label{reallocation}
\subsubsection{Introduction}\label{sec:introduction}
% What is the EH and why is it made?
%%Indeed, Samuelson wrote that, by adopting it, theorists had hoped to avoid taking economics ``out of the realm of science into the realm of genuine history''~\cite[p.~12] {Samuelson1968}.
Paul Samuelson identified the ``ergodic hypothesis'' in the mindset of classical economic theorists, defining it as ``a belief in unique long-run equilibrium independent of initial conditions''~\cite[pp.~11-12]{Samuelson1968}. Classically, the equilibrium is studied and the transient phenomena preceding it are ignored. This approach simplifies analysis greatly and is widespread. Here we present an empirical test of the validity of the ergodic hypothesis as applied to the distribution of wealth. We find it inconsistent with historical data from the United States (US), raising doubts about the conclusions of studies in which it is made.

% Transformation is needed
Economics is often concerned with growth. A growing quantity cannot be ergodic in Samuelson's sense because it does not tend to an equilibrium value. Na\"ively, then, the ergodic hypothesis seems an inappropriate modelling choice in this context, ruling out a swathe of analytical techniques. Although this is rarely stated explicitly, a common strategy to salvage these techniques is the following: find a transformation of the non-ergodic process that produces a meaningful ergodic observable. 
If such an ergodic observable can be derived, then classical techniques may still be useful. For instance,~\cite{PetersGell-Mann2016} show that utility theory can be viewed as an attempt to transform non-ergodic growing wealth into ergodic growth rates. Expectation values -- which would otherwise be misleading -- then quantify time-average growth of the decision-maker's wealth.
%\ie utility changes can be ergodic even if the underlying wealth process is not. [AA deleted. Let's say what classical technique this resurrects.]

% This is done in studies of wealth distributions
Studies of wealth distributions also employ this strategy. Individual wealth is modelled as a growing quantity. Dividing by the population average transforms this to a rescaled wealth, which is hypothesised to be ergodic. Formally, the distribution of the stochastic process for the rescaled wealth is assumed to converge to a unique and time-independent distribution. For example,~\cite{BenhabibBisinZhu2011} ``impose assumptions [\ldots] that guarantee the existence and uniqueness of a limit stationary distribution'' (p.~130). Similar formulations appear in~\cite{stiglitz1969distribution,bewley1977permanent,piketty2013theory,de2015quantitative,de2015piketty,jones2015pareto}. These studies take advantage of the simplicity with which the stationary distribution can then be analyzed, \eg to test the effects of policies encoded in model parameters.

Treating the stationary model distribution as representative of the empirical wealth distribution implies an assumption of fast convergence, \ie that the actual distribution approaches its asymptotic form on a timescale shorter than that of relevant changes in economic conditions. For example, the top rate of income tax in the US was reduced from 91 percent to 70 percent between 1963 and 1965. The next change occurred about 20 years later, in 1982, when it was reduced to 50 percent. In this example, convergence would be fast if the model distribution were close to its asymptotic form after, say, 5 years. Convergence would be slow if this took, say, 100 years.~\cite[p.~137] {atkinson1969timescale} argued that ``the speed of convergence makes a great deal of difference to the way in which we think about the model''. It determines the practical relevance of the stationary distribution~\cite{atkinson1969timescale,cowell2014piketty}.

% Other models
Recent research has marked a shift away from studying the stationary distribution in isolation.~\cite{gabaix2015dynamics,BermanBen-JacobShapira2016,kaymak2016evolution,berman2017revisiting} study the dynamics of wealth and income, rather than how they are distributed asymptotically. Some of these studies also consider convergence times~\cite{gabaix2015dynamics,berman2017revisiting}.

% What is the problem? What are we going to do?
There is, however, an elephant in the room. To our knowledge, the validity of the ergodic hypothesis for rescaled wealth has never been tested empirically. Here we present such a test. For the test to be meaningful, a model is required that does not assume ergodicity from the outset. It must have regions of parameter space (``regimes'') in which the ergodic hypothesis for rescaled wealth does and does not hold.
%As ergodicity depends on dynamics, the test cannot be carried out by looking at a wealth distribution in isolation. Instead, the dynamics of wealth must be considered.

% Our model
% AA20170120 - introduced reallocation here to make subsequent comments understandable
Our model satisfies this condition. Its basis is that individual wealth undergoes noisy exponential growth. Social structure is represented by a wealth reallocation mechanism in which a fraction of everyone's wealth is pooled and shared. The sign of the reallocation rate parameter determines whether a stationary distribution exists: if positive (corresponding to reallocation from richer to poorer) then it does; if negative (from poorer to richer) then it doesn't.

We estimate model parameters using three different datasets of historical wealth shares in the US population. These estimated parameters -- and not an {\it a priori} assumption -- tell us whether a stationary distribution exists. When it does, it has a Pareto tail, consistent with data and standard models~\cite{Pareto1897,DragulescuYakovenko2001}. We evaluate convergence times, when convergence is possible, to assess whether the ergodic hypothesis is acceptable in practice.

%Our results
% AA20170120 - added comment on negative reallocation
Our findings invalidate the ergodic hypothesis. The fitted reallocation rate is not robustly positive for any dataset we analyze. Indeed, for one dataset we find it to be consistently negative for the last thirty years or so. We cannot overstate our surprise at this finding. Most theorists would consider a model in which individual wealths grow independently, \ie with no reallocation, an extreme and unrealistic model of an advanced Western economy with socio-political institutions and infrastructure. We would expect to infer consistent positive reallocation from data for such an economy. We find the opposite: that, from the 1980s to the present, the US economy is best described in our model as one in which wealth is systematically reallocated from poorer to richer.

% AA20170120 - merged sentence from last para and added remark on negative reallocation
Other datasets yield reallocation rates for which a stationary distribution does exist, but with convergence times of decades or centuries. Whichever data are used, our analysis does not provide the unequivocal endorsement of the ergodic hypothesis that would justify its ubiquitous use in the field. Policy recommendations based on models which assume the existence of a stationary distribution and fast convergence may be ineffective in practice. Worse still, such inappropriately-constrained models may paint a misleading picture of reality, for example that with taxation and public spending our economies are positively redistributive. This could lead to policy prescriptions which run counter to policy goals.

% earnings
We also extend our model to treat explicitly additive changes in wealth, akin to labor income and consumption. This allows us to answer the question whether rescaled wealth is inherently unstable, or whether it is inherently stable with increases in its inequality driven by increasingly unequal earnings. We find that earnings had only a small effect on the dynamics of the wealth distribution over the last century
% -- we suspect due to a high wealth-to-income ratio -- 
and that changes in their distribution do not explain adequately the observed instability in wealth.

Our contribution is threefold. Firstly, we develop a theoretical model which describes the dynamics of wealth and allows us to test empirically the validity of the ergodic hypothesis. Naturally, this cannot be done using models in which the ergodic hypothesis is implicit.

Secondly, we use the model to assess how fast the wealth distribution converges to its asymptotic form, when this exists. We find convergence times greater than the typical intervals between changes in policy and other determinants of the distribution. This casts doubt over the ability of models with fast convergence to interpret observed changes in inequality and yield effective policy.

%Thirdly, our study contributes to a body of work examining ergodicity in economic systems. Indiscriminate use of the ergodic hypothesis can mean that non-ergodic processes are analyzed with methods appropriate only for ergodic processes. This is a severe methodological problem and it has been argued that this mismatch is behind open problems in economics~\cite{Peters2011b}. This study demonstrates the importance of establishing empirically and analytically which observables may legitimately be treated as ergodic.

Thirdly, our study extends a body of theory of economic systems without assuming ergodicity.~\cite{PetersGell-Mann2016} show that a sound decision theory can be developed by finding ergodic growth rates for non-ergodic wealth processes. In the present context,~\cite{AdamouPeters2016} derive a fundamental measure of wealth inequality from such growth rates. Elsewhere,~\cite{Peters2011b} resolves the St.~Petersburg paradox by maximizing individual performance over time and~\cite{Peters2011a} applies the same reasoning to derive an optimal leverage for stock-market investments.~\cite{PetersAdamou2013} extend this work to derive constraints on price fluctuations in freely-traded assets, resolving the equity premium puzzle of~\cite{MehraPrescott1985}.

Indiscriminate use of the ergodic hypothesis can mean that non-ergodic processes are analyzed with methods appropriate only for ergodic processes. This is a severe methodological problem, which we argue is behind many open problems in economics. Our work demonstrates the importance of establishing empirically and analytically which observables may be treated legitimately as ergodic.

%Thirdly, we find that the three analyzed US wealth datasets differ in their implications regarding ergodicity. This highlights the importance of the debate about the measurement of top wealth shares in the United States~\cite{kopczuk2015we,bricker2016measuring}.
%OP deleted statement that different conclusions about ergodicity come out of the different datasets. I know what we meant by that, but it's muddling the message. None of the datasets supports the ergodic hypothesis because none of them says there couldn't possibly be a problem with it.

%\OP{What about the fact that prevailing conditions look like they're pushing people into negative wealth and destroy the middle class? Ergodic models, generally, will have a middle class  because the distribution is contained around some kind of typical value. Non-ergodic models can have a vanishing middle class.}

%The rest of the paper is organized as follows. \secref{model} describes the wealth dynamics model we use and specifies its relationship to various traditional models. In \secref{data} we describe the data we use for our analysis, presenting the differences between datasets and the advantages and disadvantages of each. \secref{analysis} discusses the main results and their implications. \secref{conclusions} concludes.

\subsubsection{Model}\label{sec:model}

We call our model Reallocating Geometric Brownian Motion (RGBM). Individual wealth undergoes random multiplicative growth, modelled as Geometric Brownian Motion (GBM), and is reallocated among individuals by a simple pooling and sharing mechanism. Thus everyone's wealth is coupled to the total wealth in the economy. We view RGBM as a null model
%OP deleted this, not sure what it means: -- that is, a minimal explanatory model --
of an exponentially growing economy with social structure. It is intended to capture only the most general features of the dynamics of wealth.
% AA expanded this para, otherwise it takes too long to get to how RGBM actually works.

% AA20170120 - expanded to link regimes to reallocation direction
RGBM has both ergodic and non-ergodic regimes, characterised by the sign of the reallocation rate parameter. Reallocation from richer to poorer produces an ergodic regime, in which wealths are positive, distributed with a Pareto tail, and confined around their mean value. Reallocation from poorer to richer produces a non-ergodic regime, in which the population splits into two classes, characterised by positive and negative wealths which diverge away from the mean. If the reallocation rate is zero, RGBM reduces to GBM, in which individual wealths grow independently and no social structure is represented.

Wealth evolves multiplicatively under GBM. There are no additive changes akin to labor income and consumption. This is unproblematic for large wealths, where additive changes are dwarfed by capital gains. For small wealths, however, wages and consumption are significant. Indeed, empirical distributions exhibit different regularities for low and high wealths~\cite{DragulescuYakovenko2001}. There are other multiplicative effects at play. For instance, investing in one's health, housing, and education may be closer to a multiplicative investment than to wealth-depleting consumption. Nonetheless, we leave a red flag here to indicate that our model's realism is questionable for small wealths. We treat additive earnings explicitly in \secref{earnings} and find that including them in a less parsimonious model of wealth accumulation does not alter fundamentally our conclusions.

% AA moved this down one para to improve flow
We note that $t$ in our framework denotes time, rather than the age of an agent. As~\cite{meade1964efficiency} puts it, our agents ``do not marry or have children or die or even grow old'' (p.~41). Therefore, the individual in our setup is best imagined as a household or a family, \ie some long-lasting unit into which personal events are subsumed.

Finally, we add to the system a term that is absent from many other models in the literature. This term represents redistributive social structure. We imagine, as the simplest social interaction, that each individual pays a fixed proportion of its wealth, $x_i \tau dt$, into a central pot (``contributes to society'') and gets back an equal share of the pot, $\ave{x}_N\tau dt$, (``benefits from society''):
\be
dx_i=x_i \left[(\mu-\tau)dt+\sigma dW_i\left(t\right)\right]+ \ave{x}_N\tau dt.
\elabel{rgbm}
\ee

A more complex model would treat the economy as a system of agents that interact with each other through a network of relationships. These relationships include trade in goods and services, employment, paying taxes, using centrally-organised infrastructure (roads, schools, a legal system, social security, scientific research, and so on), insurance schemes, wealth transfers through inheritance and gifts, and everything else that constitutes an economic network. It would be a hopeless task to produce an exhaustive list of all these interactions, let alone include them as model components. Instead we introduce a single parameter -- the reallocation rate, $\tau$ -- to represent their net effect. If $\tau$ is positive, the direction of net reallocation is from richer to poorer; if negative, it is from poorer to richer.

Fitting $\tau$ to data will allow us to answer questions such as:
\bi
\item
what is the
%coarse-grained [AA removed: do economists know what this means?]
net reallocating effect of socio-economic structure on the wealth distribution?
\item
are observations consistent with the ergodic hypothesis that the rescaled wealth distribution converges to a stationary distribution?
\item
if so, how long does it take, after a change in conditions, for the rescaled wealth distribution to reach the stationary distribution?
\ei

To be clear, we do not want to separate different processes that affect the wealth distribution, as would be useful if we wanted to understand the effect of a specific process, say income tax, on economic inequality. We aim for the opposite -- a model that summarises in as few parameters as possible everything that affects the wealth distribution, crucially without assuming ergodicity. For example, if effects of death and inheritance were separated out explicitly with additional parameters, rather than being included in $\tau$, the fitted $\tau$ values would no longer tell us if the system as a whole is in an ergodic regime.

\subsubsection{Model behaviour}\label{sec:model_behavior}
\Eref{rgbm} is our model for the evolution of wealth with social structure and the basis for the empirical study that follows. It is instructive to write it as
\be
dx_i=\underbrace{x_i \left[\mu dt+\sigma dW_i\left(t\right)\right]}_{\text{Growth}} \;\; \underbrace{ - \;\; \tau (x_i-\ave{x}_N) dt}_{\text{Reallocation}}.
\elabel{rgbm_ou}
\ee
This can be thought of as GBM with a mean-reverting term like that of~\cite{UhlenbeckOrnstein1930} in physics and~\cite{Vasicek1977} in finance. This representation exposes the importance of the sign of $\tau$. We discuss the two regimes in turn.

\paragraph{Positive $\tau$}
For $\tau>0$, wealth, $x_i$, reverts to the population average, $\ave{x}_N$. The large-sample approximation, $\ave{x\left(t\right)}_N \propto e^{\mu t}$, is valid\footnote{Strictly speaking, the large-sample approximation and resulting rescaled-wealth process, \Eref{rgbm_ou_re}, hold only for $\tau>\tau_c$. However, $\tau_c \approx 0$ for realistic model parameters and fits to data do not allow us to distinguish it from zero. Nonetheless, the derivation of $\tau_c$ is instructive, see Appendix \ref{app:tauc}.} and yields a simple differential equation for the rescaled wealth,
\be
dy_i=y_i \sigma dW_i\left(t\right)- \tau (y_i-1) dt,
\elabel{rgbm_ou_re}
\ee
in which the common growth rate, $\mu$, has been scaled out. The distribution of $y_i\left(t\right)$ can found by solving the corresponding Fokker-Planck equation (also known as the Kolmogorov forward equation). A stationary distribution exists with a Pareto tail, see Appendix \ref{app:stat}. It is known as the inverse gamma distribution and has probability density function,
\be
\mathcal{P}\left(y\right) = \frac{\left(\zeta-1\right)^\zeta}{\Gamma\left(\zeta\right)} e^{-\frac{\zeta-1}{y}} y^{-\left(1+\zeta\right)},
\elabel{disti}
\ee
where $\zeta=1+\left(2\tau/\sigma^2\right)$ is the Pareto tail index, $\Gamma\left(\cdot\right)$ is the gamma function, and the index $i$ has been dropped. Example forms of the stationary distribution are shown in \Fref{dist}. The usual stylised facts are recovered: the larger $\sigma$ (more randomness in the returns) and the smaller $\tau$ (less social cohesion), the smaller the tail index and the fatter the tail of the distribution. Moreover, the fitted $\tau$ values we obtain in \secref{analysis} give typical $\zeta$ values between 1 and 2 for the different datasets analyzed, consistent with observed tail indices between 1.2 to 1.6~\cite{klass2006forbes,gabaix2009power,brzezinski2014wealth,vermeulen2017fat}. Thus, not only does RGBM predict a realistic functional form for the distribution of rescaled wealth, but also it admits fitted parameters which match observed tail thicknesses. The inability to do the latter is a known shortcoming in models of earnings-based wealth accumulation, see \secref{earnings}.
%corresponding to reallocation rates of $0.005$--$0.01 \text{ year}^{-1}$ in RGBM.

\Eref{rgbm_ou_re} and extensions of it have received much attention in statistical mechanics and econophysics~\cite{BouchaudMezard2000,Bouchaud2015}. As a combination of GBM and an Ornstein-Uhlenbeck process, it is a simple and analytically tractable stochastic process.~\cite{LiuSerota2016} provide an overview of the literature and known results.

\begin{figure}[!htb]
\centering
\includegraphics[width=1.0\textwidth] {./chapter_3/figs/dists.eps}
\caption{The stationary distribution for RGBM with positive $\tau$. Top -- linear scales; Bottom -- logarithmic scales.}
\flabel{dist}
\end{figure}

\paragraph{Negative $\tau$}

For $\tau<0$ the model exhibits mean repulsion rather than reversion. The ergodic hypothesis is invalid and no stationary wealth distribution exists. The population splits into those above the mean and those below the mean. Whereas in RGBM with non-negative $\tau$ it is impossible for wealth to become negative, negative $\tau$ leads to negative wealth. No longer is total economic wealth a limit to the wealth of the richest individual because the poorest develop large negative wealth. The wealth of the rich in the population increases exponentially away from the mean, and the wealth of the poor becomes negative and exponentially large in magnitude, see \Fref{regimes}. Qualitatively, this echoes the findings that the rich are experiencing higher growth rates of their wealth than the poor~\cite{Piketty2014,wolff2014household} and that the cumulative wealth of the poorest 50 percent of the American population was negative during 2008--2013~\cite{Rios20162013,WID2017}.

% AA comment on social mobility
Such splitting of the population is a common feature of non-ergodic processes. If rescaled wealth were an ergodic process, then individuals would, over long enough time, experience all parts of its distribution. People would spend 99 percent of their time as ``the 99 percent'' and 1 percent of their time as ``the 1 percent''. The social mobility that is, therefore, implicit in models that assume ergodicity might not exist in reality if that assumption is invalid. That inequality and immobility have been linked~\cite{Corak2013,LiuETAL2013,berman2017} may be unsurprising when both are viewed as consequences of non-ergodic wealth or income.

\begin{figure}[!htb]
\centering
\begin{tikzpicture}
%draw background
%\fill[draw=none, fill=lmlgrey, fill opacity=0.65] (0,0) rectangle (6,3);
%\fill[draw=none, fill=lmlgrey, fill opacity=0.25] (0,3) rectangle (6,6);

\fill[draw=none, pattern=north west lines, pattern color=black] (0,0.5) rectangle (5.9,3.5);
\fill[draw=none, pattern=crosshatch, pattern color=black] (0,3.5) rectangle (5.9,6.5);
\fill[draw=none, fill=white] (0.35,1) rectangle (5.55,3);
\fill[draw=none, fill=white] (0.35,4) rectangle (5.55,6);

%draw timeline
\draw [black,loosely dashed,ultra thick] (0,-0.5)--(0,0.5);
\draw[black,->,ultra thick,>=latex] (0,0.5)--(0,7.4) node[above left,rotate=90] {\small{ Reallocation rate ($\tau$)}};
  
% draw ticks
\draw [black,ultra thick] (-0.2,3.5)--(0.0,3.5);	\draw (-0.2,3.5) 	node[left=3pt] {\normalsize{$\scriptstyle 0$}};

%draw regime lines


%draw text

\node[black,font={\normalsize},anchor=west,text width=5cm] at (0.375,2.0) {No stationary distribution exists; wealths diverge -- some positive, some negative};
\node[black,font={\normalsize},anchor=west,text width=5cm] at (0.375,5.0) {Stationary distribution exists; some moments converge, some don't};
%\node[black,font={\footnotesize},anchor=west] at (0.1,1.3) {- No stationary distribution;};
%\node[black,font={\footnotesize},anchor=west] at (0.1,1.0) {- };
%\node[black,font={\footnotesize},anchor=west] at (0.1,0.7) {\,\, some negative};
%\node[black,font={\footnotesize},anchor=west] at (0.1,3.3) {- Stationary distribution exists;};
%\node[black,font={\footnotesize},anchor=west] at (0.1,3) {- Some moments converge,};
%\node[black,font={\footnotesize},anchor=west] at (0.1,2.7) {\,\, some don't};

%embed figs
\node[anchor=west] at (6,3.4)  {\includegraphics[height=6.5cm,keepaspectratio]{./chapter_3/figs/trajectories.eps}};
%\node[anchor=west] at (6,4.5)  {\includegraphics[height=3cm,keepaspectratio]{pos_tau1.eps}};
%\node[anchor=west] at (9.75,4.5)  {\includegraphics[height=3cm,keepaspectratio]{pos_tau3.eps}};
%\node[anchor=west] at (6,1.5)  {\includegraphics[height=3cm,keepaspectratio]{pos_tau2.eps}};

\draw [black,densely dashed,ultra thick] 			(0,3.5)--(13.5,3.5);

%labels
\node[black,font=\normalsize\sffamily,anchor=west,text width=4.5cm] at (0.2,6.75) {A)};
\node[black,font=\normalsize\sffamily,anchor=west,text width=4.5cm] at (5.85,6.75) {B)};
\node[black,font=\normalsize\sffamily,anchor=west,text width=4.5cm] at (9.7,6.75) {C)};
\node[black,font=\normalsize\sffamily,anchor=west,text width=4.5cm] at (5.85,3.15) {D)};
\node[black,font=\normalsize\sffamily,anchor=west,text width=4.5cm] at (9.7,3.15) {E)};
  
\end{tikzpicture}
\caption{Regimes of RGBM. A) $\tau=0$ separates the two regimes of RGBM. For $\tau>0$, a stationary wealth distribution exists. For $\tau<0$, no stationary wealth distribution exists and wealths diverge. B) Simulations of RGBM with $N=1000$, $\mu=0.021 \text{ year}^{-1}$ (presented after rescaling by $e^{\mu t}$), $\sigma=0.14\text{ year}^{-1/2}$, $x_i\left(0\right)=1$, $\tau=0.15 \text{ year}^{-1}$. Magenta lines: largest and smallest wealths, blue lines: five randomly chosen wealth trajectories, black line: sample mean. C) The stationary distribution to which the system in B) converges. Inset: same distribution on linear scales. D) Similar to B), with $\tau=-0.15 \text{ year}^{-1}$. E) in the $\tau<0$ regime, no stationary wealth distribution exists.}
\flabel{regimes}
\end{figure}

\subsubsection{Data}\label{sec:data}

\subsubsection{Wealth share data}

We analyze the wealth shares of the top quantiles of the US population, as estimated by three sources using different methods:

\bi
\item
The income tax method (``capitalization method'') that uses information on capital income from individual income tax returns to estimate the underlying stock of wealth~\cite{SaezZucman2014,WID2017}. ``If we can observe capital income $k = rW$, where $W$ is the underlying value of an asset and $r$ is the known rate of return, then we can estimate wealth based on capital income and capitalization factor $1/r$ defined using the appropriate choice of rate of return''~\cite[p.~54] {kopczuk2015we}. Data availability: the wealth shares of the top 5, 0.5, 0.1 and 0.01 percent for 1917--2012 and of the top 10 and 1 percent for 1913--2014 (annually).
\item
The estate multiplier method that uses data from estate tax returns to estimate wealth for the upper tail of the wealth distribution~\cite{kopczuk2004top}. ``The basic idea is to think of decedents as a sample from the living population. The individual-specific mortality rate $m_i$ becomes the sampling rate. If $m_i$ is known, the distribution for the living population can be simply estimated by reweighting the data for decedents by inverse sampling weights $1/m_i$, which are called `estate multipliers' ''~\cite[p.~53] {kopczuk2015we}. Data availability: the wealth shares of the top 1, 0.5, 0.25, 0.1, 0.05 and 0.01 percent for 1916--2000 (annually, with several missing years).
\item
The survey-based method that uses data from the Survey of Consumer Finances (SCF) conducted by the Federal Reserve, plus defined-benefit pension wealth, plus the wealth of the members of the Forbes 400~\cite{bricker2016measuring2}. Data availability: the wealth shares of the top 1 and 0.1 percent for 1989--2013 (for every three years).
\ei

These sources are based on different datasets and for different time periods. In the overlapping periods, they sometimes report markedly different wealth share estimates (see \Fref{data1}).

\begin{figure}[!htb]
\centering
\includegraphics[width=1.0\textwidth] {./chapter_3/figs/data.eps}
\caption{The top wealth shares in the US, 1913--2014. Sources --~\cite{SaezZucman2014,WID2017} (blue);~\cite{kopczuk2004top} (black);~\cite{bricker2016measuring2} (grey).}
\flabel{data1}
\end{figure}

\cite{kopczuk2015we} reviewed the advantages and disadvantages of the different methods (see also the comment by Kopczuk on~\cite{bricker2016measuring2}). He observed that ``the survey-based and estate tax methods suggest that the share of wealth held by the top 1 percent has not increased much in recent decades, while the capitalization method suggests that it has''~\cite[p.~48] {kopczuk2015we}.

Which method best reflects the recent trends in wealth inequality is a matter of ongoing debate. Each method suffers from bias. For example, the survey-based method suffers from some underrepresentation of families who belong to the top end of the distribution. The income tax method suffers from some practical difficulties -- ``not all categories of assets generate capital income that appears on tax returns. [\ldots] Owner-occupied housing does not generate annual taxable capital income''~\cite[p. 54] {kopczuk2015we}. The estate tax method suffers from the need to accurately estimate mortality rates for the wealthy, known to be lower than those for the rest of the population. We refer the reader to~\cite{kopczuk2015we,bricker2016measuring2} for a thorough discussion. We analyze each data source separately.

\subsubsection{Wealth Growth Rate}
% AA20170120 - added new para and deleted old paras
We find numerically that the results of our analysis do not depend on $\mu$. This is because wealth shares depend only on the distribution of rescaled wealth and, for $\tau>0$, it is possible to scale out $\mu$ completely from the wealth dynamic to obtain \Eref{rgbm_ou_re} for rescaled wealth. The fitted $\tau<0$ values we find are not large or persistent enough to make our simulations significantly $\mu$-dependent. However, formally, since we allow negative $\tau$, we must simulate \Eref{rgbm} and not \Eref{rgbm_ou_re}. This requires us to specify a value of $\mu$, which we estimate as $\mu=0.021\pm 0.001 \text{ year}^{-1}$ by a least-squares fit of historical per-capita private wealth in the US~\cite{PikettyZucman2014} to an exponential growth curve.

\subsubsection{Volatility}
We must also specify the volatility parameter, $\sigma$, in \Eref{rgbm}. In principle, this can vary with time. We have no access to real individual wealth trajectories, so we resort to estimating $\sigma\left(t\right)$ from other data. We find numerically that our results are not very sensitive to the details, so we need only a good ``ballpark'' estimate. We obtain that by assuming that the volatility in individual wealths tracks the volatility in the values of the companies that constitute the commercial and industrial base of the national economy. Therefore, for each year, we estimate $\sigma\left(t\right)$ as the standard deviation of daily logarithmic changes of the Dow Jones Industrial Average~\cite{Quandl2016}, which we annualise by multiplying by $\left(250/\text{year}\right)^{1/2}$. The values usually lie between $0.1$ and $0.2 \text{ year}^{-1/2}$, with an average of $0.16\text{ year}^{-1/2}$. Running our empirical analysis with constant $\sigma$ in this range had little effect on our results (see Appendix \ref{app:fixed_sig}) so, for simplicity, we present the analysis using $\sigma\left(t\right)=0.16\text{ year}^{-1/2}$ for all $t$.

Fitting $\sigma$ to stock market data means that we have only one model parameter -- the effective reallocation rate, $\tau\left(t\right)$ -- to fit to the historical wealth shares.

\subsubsection{Empirical Analysis}\label{sec:analysis}
The goal of the empirical analysis is to estimate $\tau\left(t\right)$ from the historical wealth data, using RGBM as our model. This estimation allows us to address two main questions:

\bi
\item[1.] Is it valid to assume ergodicity for the dynamics of relative wealth in the US? For the ergodic hypothesis to be valid, fitted values of $\tau\left(t\right)$ would have to be robustly positive.
\item[2.] If $\tau\left(t\right)$ is indeed positive, how long does it take for the distribution to converge to its asymptotic form?
\ei

We fit a time series, $\tau\left(t\right)$, that reproduces the annually observed wealth shares in the three datasets (see \secref{data}): Income tax-based~\cite{SaezZucman2014,WID2017}, estate tax-based~\cite{kopczuk2004top} and survey-based~\cite{bricker2016measuring2}. The wealth share, $S_q$, is defined as the proportion of total wealth, $\sum_i^N x_i$, owned by the richest fraction $q$ of the population, \eg $S_{10\%}=80 \text{ percent}$ means that the richest 10 percent of the population own 80 percent of the total wealth.

For an empirical wealth share time series, $S^{\text{data}}_q\left(t\right)$, we proceed as follows.

\bi
\item[ -- Step 1]
Initialise $N$ individual wealths, $\{x_i\left(t_0\right)\}$, as random variates of the inverse gamma distribution with parameters chosen to match $S^{\text{data}}_q\left(t_0\right)$.
\item[ -- Step 2]
Propagate $\{x_i\left(t\right)\}$ according to \Eref{rgbm} over $\Dt$,
%OP changed this: $\Dt$ is not always one year.
using the value of $\tau$ that minimises the difference between the wealth share in the modelled population, $S^{\text{model}}_q\left(t+\Dt, \tau\right)$, and $S^{\text{data}}_q\left(t+\Dt\right)$. We use the Nelder-Mead algorithm~\cite{NelderMead1965}.
\item[ -- Step 3]
Repeat Step 2 until the end of the time series.
\ei

We consider historical wealth shares of the richest $q=$ 10, 5, 1, 0.5, 0.25, 0.1, 0.05 and 0.01 percent and obtain time series of fitted effective reallocation rates, $\tau_q\left(t\right)$, shown in \Fref{tau}.
For each value of $q$ we perform a run of the simulation for $N=10^8$. Since in practice $dW$ is randomly chosen, each run of the simulation will result in slightly different $\tau_q\left(t\right)$ values. However, we found that the differences between such calculations are negligible. 

\begin{figure}[!htb]
\centering
\includegraphics[width=1.0\textwidth] {./chapter_3/figs/tau_top1.eps}
\caption{Fitted effective reallocation rates. Calculations done using $\mu=0.021 \text{ year}^{-1}$ and $\sigma=0.16 \text{ year}^{-1/2}$. Top: $\tau_{1\%}\left(t\right)$ (black) and $\widetilde{\tau}_{1\%}\left(t\right)$ (red). Translucent envelopes indicate one standard error in the moving averages. Bottom: $S^{\text{data}}_{1\%}$ (blue), $S^{\text{model}}_{1\%}$ based on the annual $\tau_{1\%}\left(t\right)$ (dashed black), based on the 10-year moving average $\widetilde{\tau}_{1\%}\left(t\right)$ (red).}
\flabel{tau}
\end{figure}

\Fref{tau} (top) shows large annual fluctuations in $\tau_q\left(t\right)$. We are interested in longer-term changes in reallocation driven by structural economic and political changes. To elucidate these we smooth the data by taking a central 10-year moving average, $\widetilde{\tau}_q\left(t\right)$, where the window is truncated at the ends of the time series. To ensure the smoothing does not introduce artificial biases, we reverse the procedure and use $\widetilde{\tau}_q\left(t\right)$ to propagate the initially inverse gamma-distributed $\{x_i\left(t_0\right)\}$ and determine the wealth shares $S^{\text{model}}_q\left(t\right)$. The good agreement with $S^{\text{data}}_q\left(t\right)$ suggests that the smoothed $\widetilde{\tau}_q\left(t\right)$ is meaningful, see \Fref{tau} (bottom).

For the income tax method wealth shares~\cite{SaezZucman2014}, the effective reallocation rate, $\widetilde{\tau}\left(t\right)$, has been negative -- \ie from poorer to richer -- since the mid-1980s. This holds for all of the inequality measures we derived from this dataset.

For the survey-based wealth shares~\cite{bricker2016measuring2}, we observe briefer periods in which $\widetilde{\tau}\left(t\right) < 0$. The same is true for the estate tax data~\cite{kopczuk2004top}, see \Fref{shares_comp}. When $\tau\left(t\right)$ is positive, relevant convergence times are very long compared to the time scales of policy changes, namely at least several decades.

All three datasets indicate that making the ergodic hypothesis is an unwarranted restriction on models and analyses. The hypothesis makes it impossible to observe and reason about the most dramatic qualitative features of wealth dynamics, such as rising inequality, negative reallocation, negative wealth, and social immobility.

\begin{figure}[!htb]
\centering
\includegraphics[width=1.0\textwidth] {./chapter_3/figs/tau_top1_top0i1_datasets.eps}
\caption{Effective reallocation rates for different datasets.}
\flabel{shares_comp}
\end{figure}

\subsubsection{Convergence times}
In the ergodic regime it is possible to calculate how fast the wealth shares of different quantiles converge to their asymptotic value. We do this numerically. Starting with a population of equal wealths and assuming $\mu=0.021 \text{ year}^{-1}$, $\sigma=0.16 \text{ year}^{-1/2}$, and $\tau = 0.04\text{ year}^{-1}$, we let the system equilibrate for 3000 years, long enough for the distribution to reach its asymptotic form to numerical precision. We then create a ``shock'', by changing $\tau$ to a different ``shock value'', and allow the system to equilibrate again for 3000 years, see top panel of \Fref{conv}. Following the shock, the wealth shares converge to their asymptotic values. We fit this convergence numerically with an exponential function and interpret the inverse of the exponential convergence rate as the convergence time. The bottom panel of \Fref{conv}  shows the convergence times versus the shock value of $\tau$.

\begin{figure}[!htb]
\centering
\includegraphics[width=1.0\textwidth] {./chapter_3/figs/convergence.eps}
\caption{Wealth share convergence time. Top: The convergence of the wealth share for $q=$ 10 percent (blue), $q=$ 1 percent (yellow) and $q=$ 0.1 percent (purple) following a change in the value of $\tau$ from $0.04\text{ year}^{-1}$ to $0.03\text{ year}^{-1}$ (solid), $0.025\text{ year}^{-1}$ (dashed) and $0.02\text{ year}^{-1}$ (dotted). Bottom: The wealth share exponential convergence time for $q=$ 10 percent (blue), $q=$ 1 percent (yellow) and $q=$ 0.1 percent (purple) as a function of $\tau$.}
\flabel{conv}
\end{figure}

In addition, it is possible to calculate the convergence time of the variance of the stationary distribution (and other cumulants and moments of interest). In the ergodic regime the stationary distribution has a finite variance only if $\tau > \sigma^2/2$~\cite{LiuSerota2016}. Convergence of the actual variance to the stationary variance occurs exponentially over a timescale $1/(2\tau - \sigma^2)$. \Fref{convar} shows the convergence times for different values of $\sigma$. See Appendix \ref{app:var_conv} for more details.

\begin{figure}[!htb]
\centering
\includegraphics[width=1.0\textwidth] {./chapter_3/figs/variance_convergence.eps}
\caption{Variance convergence time}
\flabel{convar}
\end{figure}

Convergence times for wealth shares and variance are long, ranging from a few decades to several centuries. This implies that empirical studies which assume ergodicity and fast convergence will be inconsistent with the data. To test this, we simulate such a study by performing a different RGBM parameter fit. We find the reallocation rates, $\tau^\text{eqm}_q\left(t\right)$, that generate stationary distributions consistent with observed wealth shares. In other words, we assume instantaneous convergence.

\Fref{asymptau} contrasts $\tau^\text{eqm}_{1\%}\left(t\right)$ assuming ergodicity with $\widetilde{\tau}_{1\%}\left(t\right)$ without assuming ergodicity (using the income tax method dataset). If convergence were always possible and fast, then the two values would be identical within statistical uncertainties. They are not. In addition, the generally large discrepancies between the wealth inequality implied by $\tau^\text{eqm}_{1\%}\left(t\right)$ (bottom panel, \Fref{asymptau}, green line) and as observed (bottom panel, \Fref{asymptau}, blue line) indicate that the wealth distribution does not stay close to its asymptotic form. This means that the long convergence times we calculate are a practical methodological problem for conventional studies.

\begin{figure}[!htb]
\centering
\includegraphics[width=1.0\textwidth] {./chapter_3/figs/tau_eqm_top1.eps}
\caption{Comparison of dynamic and equilibrium reallocation rates. Top: $\widetilde{\tau}_{1\%}\left(t\right)$ (red, same as in the top of \Fref{tau}). $\tau^\text{eqm}_{1\%}\left(t\right)$ (green), defined such that $\lim_{t'\to\infty} S^{\text{model}}_{1\%}\left(t',\tau^\text{eqm}_{1\%}\left(t\right)\right)=S^{\text{data}}_{1\%}\left(t\right)$. It is impossible by design for this value to be negative. The significant difference between the red and green lines demonstrates that the fast convergence assumption is invalid for the problem under consideration. Bottom: $S^{\text{data}}_{1\%}$ (blue), $S^{\text{model}}_{1\%}$ based on the 10-year moving average $\widetilde{\tau}_{1\%}\left(t\right)$ (red), based on $\tau^\text{eqm}_{1\%}\left(t\right)$ (green). The reallocation rates found under the fast convergence assumption generate model wealth shares which bear little relation to reality.}
\flabel{asymptau}
\end{figure}

\subsubsection{Conclusions}\label{sec:conclusions}
Studies of economic inequality often assume ergodicity of relative wealth. This assumption also goes under the headings of equilibrium, stationarity, or stability~\cite{AdamouPeters2016}. Specifically, it is assumed that:
\bi
\item[1.] the system can equilibrate, \ie a stationary distribution exists to which the observed distribution converges in the long-time limit; and
\item[2.] the system equilibrates quickly, \ie the observed distribution gets close to the stationary distribution after a time shorter than other relevant timescales, such as the time between policy changes.
\ei
Assumption 2 is often left unstated, but it is necessary for the stationary (model) distribution to resemble the observed (real) distribution. This matters because the stationary distribution is often a key object of study -- model parameters are found by fitting the stationary distribution to observed inequality, and effects of various model parameters on the stationary distribution are explored.

We do not assume ergodicity. Fitting $\tau$ in RGBM allows the data to speak without constraint as to whether the ergodic hypothesis is valid. We find it to be invalid because:
\bi
\item[A.] We observe negative $\tau$ values in all datasets analyzed, most notably using the income tax method, especially since about 1980. The wealth distribution is non-stationary and inequality increases for as long as these conditions prevail.
\item[B.] When we observe positive $\tau$, the associated convergence times are mostly of the order of decades or centuries, see \Fref{shares_comp} and \Fref{conv} (bottom). They are much longer than the periods over which economic conditions and policies change -- they are the timescales of history rather than of politics.
\ei
The ergodic hypothesis precludes what we find. Item A above corresponds to reallocation that moves wealth from poorer to richer individuals, which is inconsistent with the ergodic hypothesis. In this sense the ergodic hypothesis is a set of blindfolds, hiding from view the most dramatic economic conditions. For the most recent data, the system is in a state best described by non-ergodic RGBM, $\tau<0$~\cite{SaezZucman2014,WID2017} or $\tau \approx 0$~\cite{bricker2016measuring2}. Therefore, each time we observe the wealth distribution, we see a snapshot of it either in the process of diverging or very far from its asymptotic form. It is much like a photograph of an explosion in space: it will show a fireball whose finite extent tells us nothing of the eventual distance between pieces of debris.

We also find that changes in the earnings distribution do not provide an adequate alternative explanation of the described dynamics of the wealth distribution. Although earnings have become more unequal over the recent decades in which wealth inequality has increased, their effect on the wealth distribution has been small and generally stabilizing rather than destabilizing. Treating earnings explicitly in our model does not change fundamentally our conclusions.

The economic phenomena that trouble theorists most -- such as diverging inequality, social immobility, and the emergence of negative wealth -- are difficult to reproduce in a model that assumes ergodicity. In our simple model, this is easy to see: in the ergodic regime, $\tau>0$, our model cannot reproduce these phenomena at all. One may be tempted to conclude that their existence is a sign of special conditions prevailing in the real world -- collusion and conspiracies. But if we admit the possibility of non-ergodicity, $\tau\leq0$, it becomes clear that these phenomena can easily emerge in an economy that does not actively guard against them.

\subsubsection{The derivation of the stationary distribution}\label{app:stat}

We start again with the SDE for the rescaled wealth, 
\be
dy= \sigma\,y\,dW - \tau\left(y - 1\right)dt.
\ee
This is an It\^o equation with drift term 
$A=\tau(y - 1)$ and diffusion term $B=y \sigma$.

Such equations imply ordinary second-order differential equations that describe the evolution of the pdf, called Fokker-Planck equations. 
The Fokker-Planck equation describes the change in probability density, at any point in (relative-wealth) space, due to the action of the drift term (like advection in a fluid) and due to the diffusion term (like heat spreading). In this case, we have
\be
\frac{dp\left(y,t\right)}{dt}=\frac{\partial}{\partial y} \left[Ap\left(y,t\right)\right]+\frac{1}{2} \frac{\partial^2}{\partial y^2}\left[B^2 p\left(y,t\right)\right].
\ee

The steady-state Fokker-Planck equation for the pdf $p\left(y\right)$ is obtained by setting the time derivative to zero,
\be
\frac{\sigma^2}{2}\left(y^2 p\right)_{yy} + \tau\left[\left(y-1\right)p\right]_y = 0.
\elabel{fokker_planck}
\ee
Positive wealth subjected to continuous-time multiplicative dynamics with non-negative reallocation can never reach zero. Therefore, we solve \Eref{fokker_planck} with boundary condition $p\left(0\right)=0$ to give
\be
p\left(y\right) = C\left(\zeta\right) e^{-\frac{\zeta-1}{y}}y^{-\left(1+\zeta\right)}\,,
\ee
where 
\be
\zeta = 1+\frac{2\tau}{\sigma^2}
\ee
and
\be
C\left(\zeta\right) = \frac{\left(\zeta -1\right)^\zeta}{\Gamma \left(\zeta \right)}\,,
\ee
with the gamma function $\Gamma\left(\zeta\right) = \int_0^\infty x^{\zeta-1} e^{-x}\,\mathrm{d}x$. The distribution has a power-law tail as $y\to\infty$, resembling Pareto's often confirmed observation that the frequency of large wealths tends to decay as a power law. The exponent of the power law, $\zeta$, is called the Pareto parameter and is one measure of economic inequality.

\subsubsection{The derivation of the variance convergence time}\label{app:var_conv}

Our key finding is that under currently prevailing economic conditions it is not safe to assume the existence of stationary wealth distributions in models of wealth dynamics. 
Nevertheless, we present some results for the regime of our model where a stationary distribution exists.
The full form of the distribution is derived in Appendix \ref{app:stat}. Because it has a power-law tail for large wealths, only the lower moments of the distribution exist, while higher moments diverge.
Below, we derive a condition for the convergence of the variance and calculate its convergence time.

The variance of $y$ is a combination of the first moment, $\ave{y}$ (the average), and the second moment, $\ave{y^2}$:
\be
V\left(y\right)=\ave{y^2}-\ave{y}^2
\ee
We thus need to find $\ave{y}$ and $\ave{y^2}$ in order to determine the variance. 
The first moment of the rescaled wealth is, by definition, $\ave{y}=1$. 

To find the second moment, we start with the SDE for the rescaled wealth:
\be
dy = \sigma y\,dW - \tau\left(y - 1\right)\,dt.
\elabel{rescaledSDE}
\ee

This is an It\^o process, which implies that an increment, $df$, in some (twice-differentiable) function $f\left(y,t\right)$ will also be an It\^o process, and such increments can be found by Taylor-expanding to second order in $dy$ as follows:
\be
df = \frac{\partial f}{\partial t} dt + \frac{\partial f}{\partial y} dy + \frac{1}{2}\frac{\partial^2 f}{\partial y^2} dy^2\,.
\ee
We insert $f\left(y,t\right)=y^2$ and obtain
\be
d \left(y^2\right) = 2ydy + \left(dy\right)^2\,.
\elabel{diff2}
\ee

We substitute $dy$ in \Eref{diff2}, which yields terms of order $dW$, $dt$, $dW^2$, $dt^2$, and $\left(dW\,dt\right)$. The scaling of Brownian motion allows us to replace $dW^2$ by $dt$, and we ignore $o\left(dt\right)$ terms. This yields
\bea
d \left(y^2\right) = 2\sigma y^2\,dW - \left(2\tau-\sigma^2\right) y^2\,dt + 2\tau y\,dt %+ \tau^2\left(y - 1\right)^2\,dt^2 - \st{\tau\left(y - 1\right)\,\sigma y\,dW\,dt}
\eea
Taking expectations on both sides, and using $\ave{y}=1$, produces an ordinary differential equation for the second moment:
\be
\frac{d \langle y^2 \rangle}{dt} = -\left(2\tau - \sigma^2\right) \langle y^2 \rangle + 2\tau
\elabel{avediff2}
\ee
with solution
\be
\langle y\left(t\right)^2 \rangle = \frac{2\tau}{2\tau - \sigma^2} + \left(\langle y\left(0\right)^2 \rangle - \frac{2\tau}{2\tau - \sigma^2}\right) e^{-\left(2\tau - \sigma^2\right)t}\,.
\elabel{avediff3}
\ee

The variance $V\left(t\right)=\langle y\left(t\right)^2 \rangle-1$ therefore follows
\be
V\left(t\right) = V_{\infty}+\left(V_0 - V_{\infty}\right)e^{-\left(2\tau - \sigma^2\right)t}\,,
\elabel{var1}
\ee
where $V_0$ is the initial variance and
\be
V_{\infty} = \frac{2\tau}{2\tau - \sigma^2}\,.
\elabel{varinf}
\ee
$V$ converges in time to the asymptote, $V_{\infty}$, provided the exponential in \Eref{var1} is decaying. 
This can be expressed as a condition on $\tau$
\be
\tau > \frac{\sigma^2}{2} \,.
\ee

Clearly, for negative values of $\tau$ the condition cannot be satisfied, and the variance (and inequality) of the wealth distribution will diverge. 
In the regime where the variance exists, $\tau > \sigma^2/2$, it also follows from \Eref{var1} that the convergence time of the variance is $1/\left(2\tau - \sigma^2\right)$.

As $\tau$ increases, increasingly high moments of the distribution become convergent to some finite value. 
The above procedure for finding the second moment (and thereby the variance) can be applied to the $k^\text{th}$ moment, just by changing the second power $y^2$ to $y^k$, and any other cumulant can therefore be found as a combination of the relevant moments. 
For instance~\cite{LiuSerota2016} also compute the third cumulant.

\end{comment}
